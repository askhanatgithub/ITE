{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "52542919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8367c892d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from geomloss import SamplesLoss\n",
    "from torch.autograd import Function\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.functional import normalize\n",
    "#from torchmetrics.classification import BinaryAccuracy\n",
    "from torchmetrics.classification import BinaryF1Score\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e50bd733",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TarNet(nn.Module):\n",
    "    def __init__(self,params):\n",
    "        super(TarNet, self).__init__()\n",
    "        self.encoder1 = nn.Linear(25, params['RL11'])\n",
    "        self.encoder2 = nn.Linear(params['RL11'], params['RL21'])\n",
    "        self.encoder3 = nn.Linear(params['RL21'], params['RL32'])\n",
    "\n",
    "        self.regressor1_y0 = nn.Sequential(\n",
    "            nn.Linear(params['RL32'], params['RG012']),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=.01),\n",
    "        )\n",
    "        self.regressor2_y0 = nn.Sequential(\n",
    "            nn.Linear(params['RG012'], params['RG022']),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=.01),\n",
    "        )\n",
    "        self.regressorO_y0 = nn.Linear(params['RG022'], 1)\n",
    "\n",
    "        self.regressor1_y1 = nn.Sequential(\n",
    "            nn.Linear(params['RL32'], params['RG112']),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=.01),\n",
    "        )\n",
    "        self.regressor2_y1 = nn.Sequential(\n",
    "            nn.Linear(params['RG112'], params['RG122']),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=.01),\n",
    "        )\n",
    "        self.regressorO_y1 = nn.Linear(params['RG122'], 1)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = nn.functional.elu(self.encoder1(inputs))\n",
    "        x = nn.functional.elu(self.encoder2(x))\n",
    "        phi = nn.functional.elu(self.encoder3(x))\n",
    "\n",
    "        out_y0 = self.regressor1_y0(phi)\n",
    "        out_y0 = self.regressor2_y0(out_y0)\n",
    "        y0 = self.regressorO_y0(out_y0)\n",
    "\n",
    "        out_y1 = self.regressor1_y1(phi)\n",
    "        out_y1 = self.regressor2_y1(out_y1)\n",
    "        y1 = self.regressorO_y1(out_y1)\n",
    "\n",
    "        concat = torch.cat((y0, y1), 1)\n",
    "        return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "70c58121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial,i):\n",
    "\n",
    "    params = {\n",
    "          'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
    "          'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\"]),\n",
    "          'batch_size':trial.suggest_int('batch_size', 8, 256),\n",
    "          'RL11':trial.suggest_int('RL11', 16, 512),\n",
    "          'RL21': trial.suggest_int('RL21', 16, 512),\n",
    "          'RL32': trial.suggest_int('RL32', 16, 512),\n",
    "          'RG012':trial.suggest_int('RG012', 16, 512),\n",
    "        'RG022':trial.suggest_int('RG022', 16, 512),\n",
    "        'RG112':trial.suggest_int('RG112', 16, 512),\n",
    "        'RG122':trial.suggest_int('RG122', 16, 512),\n",
    "          \n",
    "          }\n",
    "\n",
    "    model = TarNet(params)\n",
    "\n",
    "    pehe,model= train_evaluate(params, model, trial,i)\n",
    "\n",
    "    return pehe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48800d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y.astype(np.float32))\n",
    "        self.len = self.X.shape[0]\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "   \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d80cf340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_type,file_num):\n",
    "\n",
    "    if(data_type=='train'):\n",
    "        data=pd.read_csv(f\"Dataset/IHDP_a/ihdp_npci_train_{file_num}.csv\")\n",
    "    else:\n",
    "        data = pd.read_csv(f\"Dataset/IHDP_a/ihdp_npci_test_{file_num}.csv\")\n",
    "\n",
    "    x_data=pd.concat([data.iloc[:,0], data.iloc[:, 1:30]], axis = 1)\n",
    "    #x_data=data.iloc[:, 5:30]\n",
    "    y_data=data.iloc[:, 1]\n",
    "    return x_data,y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2319f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(x_data,y_data,batch_size):\n",
    "\n",
    "    x_train_sr=x_data[x_data['treatment']==0]\n",
    "    y_train_sr=y_data[x_data['treatment']==0]\n",
    "    x_train_tr=x_data[x_data['treatment']==1]\n",
    "    y_train_tr=y_data[x_data['treatment']==1]\n",
    "\n",
    "\n",
    "    train_data_sr = Data(np.array(x_train_sr), np.array(y_train_sr))\n",
    "    train_dataloader_sr = DataLoader(dataset=train_data_sr, batch_size=batch_size)\n",
    "\n",
    "    train_data_tr = Data(np.array(x_train_tr), np.array(y_train_tr))\n",
    "    train_dataloader_tr = DataLoader(dataset=train_data_tr, batch_size=batch_size)\n",
    "\n",
    "\n",
    "    return train_dataloader_sr, train_dataloader_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b92cc291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_loss(concat_true, concat_pred):\n",
    "    #computes a standard MSE loss for TARNet\n",
    "    y_true = concat_true[:, 0] #get individual vectors\n",
    "    t_true = concat_true[:, 1]\n",
    "\n",
    "    y0_pred = concat_pred[:, 0]\n",
    "    y1_pred = concat_pred[:, 1]\n",
    "\n",
    "    #Each head outputs a prediction for both potential outcomes\n",
    "    #We use t_true as a switch to only calculate the factual loss\n",
    "    loss0 = torch.sum((1. - t_true) * torch.square(y_true - y0_pred))\n",
    "    loss1 = torch.sum(t_true * torch.square(y_true - y1_pred))\n",
    "    #note Shi uses tf.reduce_sum for her losses instead of tf.reduce_mean.\n",
    "    #They should be equivalent but it's possible that having larger gradients accelerates convergence.\n",
    "    #You can always try changing it!\n",
    "    return loss0 + loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "536f4a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_pehe(data,y,model):\n",
    "    #data,y=get_data('test',i)\n",
    "\n",
    "    data=data.to_numpy()\n",
    "    data=torch.from_numpy(data.astype(np.float32))\n",
    "\n",
    "\n",
    "\n",
    "    concat_pred=model(data[:,5:30])\n",
    "    #dont forget to rescale the outcome before estimation!\n",
    "    #y0_pred = data['y_scaler'].inverse_transform(concat_pred[:, 0].reshape(-1, 1))\n",
    "    #y1_pred = data['y_scaler'].inverse_transform(concat_pred[:, 1].reshape(-1, 1))\n",
    "    cate_pred=concat_pred[:,1]-concat_pred[:,0]\n",
    "    cate_true=data[:,4]-data[:,3] #Hill's noiseless true values\n",
    "\n",
    "\n",
    "    cate_err=torch.mean( torch.square( ( (cate_true) - (cate_pred) ) ) )\n",
    "\n",
    "    return torch.sqrt(cate_err).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5226d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_cal(X_data,y_data,net):\n",
    "    \n",
    "    x_train_sr=X_data[X_data['treatment']==0]\n",
    "    y_train_sr=y_data[X_data['treatment']==0]\n",
    "    x_train_tr=X_data[X_data['treatment']==1]\n",
    "    y_train_tr=y_data[X_data['treatment']==1]\n",
    "    xs_t=x_train_sr.iloc[:,0].to_numpy()\n",
    "    xt_t=x_train_tr.iloc[:,0].to_numpy()\n",
    "    \n",
    "    xs=x_train_sr.iloc[:,5:30].to_numpy()\n",
    "    xt=x_train_tr.iloc[:,5:30].to_numpy()\n",
    "    xs_t=torch.from_numpy(xs_t.astype(np.float32))\n",
    "    xt_t=torch.from_numpy(xt_t.astype(np.float32))\n",
    "    y_train_sr=y_train_sr.to_numpy()\n",
    "    y_train_tr=y_train_tr.to_numpy()\n",
    "    xs=torch.from_numpy(xs.astype(np.float32))\n",
    "    xt=torch.from_numpy(xt.astype(np.float32))\n",
    "    \n",
    "    y_train_sr=torch.from_numpy(y_train_sr.astype(np.float32))\n",
    "    y_train_tr=torch.from_numpy(y_train_tr.astype(np.float32))\n",
    "    \n",
    "    \n",
    "    input_data=torch.cat((xs,xt),0)\n",
    "    true_y=torch.unsqueeze(torch.cat((y_train_sr,y_train_tr),0), dim=1)\n",
    "    true_t=torch.unsqueeze(torch.cat((xs_t,xt_t),0), dim=1)\n",
    "    \n",
    "    \n",
    "    concat_true=torch.cat((true_y,true_t),1)\n",
    "    concat_pred=net(input_data)\n",
    "    loss=regression_loss(concat_true, concat_pred)\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c05852e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#criterion_reg=nn.MSELoss()\n",
    "#criterion_reg=regression_loss(concat_true,concat_pred)\n",
    "epochs=300\n",
    "#batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bcb7c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[]\n",
    "val_loss=[]\n",
    "pehe_error=[]\n",
    "num_files=2\n",
    "def train_evaluate(param, model, trial,file_num):\n",
    "    #for nf in range(1,num_files):\n",
    "    x_data,y_data=get_data('train',file_num)\n",
    "    X_train, X_val,y_train, y_val = train_test_split(x_data,y_data ,\n",
    "                                       random_state=42, \n",
    "                                       test_size=0.20)\n",
    "    \n",
    "    #net=TarNet(25,.01)\n",
    "    #opt_net = torch.optim.Adam(net.parameters(), lr=1e-4)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    \n",
    "    optimizer = getattr(optim, param['optimizer'])(model.parameters(), lr= param['learning_rate'])\n",
    "    \n",
    "    if use_cuda:\n",
    "\n",
    "        #model = model.cuda()\n",
    "        model = model\n",
    "        #criterion = criterion.cuda()\n",
    "\n",
    "    for ep in range(1,epochs+1 ):\n",
    "\n",
    "        train_dataloader_sr, train_dataloader_tr=get_dataloader(X_train,y_train,param['batch_size'])\n",
    "\n",
    "        for batch_idx, (train_source_data, train_target_data) in enumerate(zip(train_dataloader_sr, train_dataloader_tr)):\n",
    "\n",
    "            xs,ys=train_source_data\n",
    "            xt,yt=train_target_data\n",
    "\n",
    "            xs_train=xs[:,5:30]\n",
    "            xt_train=xt[:,5:30]\n",
    "\n",
    "            train_x=torch.cat((xs_train,xt_train),0)\n",
    "            train_y=torch.unsqueeze(torch.cat((ys,yt),0), dim=1)\n",
    "            true_t=torch.unsqueeze(torch.cat((xs[:,0],xt[:,0]),0), dim=1)\n",
    "            concat_true=torch.cat((train_y,true_t),1)\n",
    "            concat_pred=model(train_x)\n",
    "\n",
    "            model.zero_grad()\n",
    "\n",
    "            #source_mse=criterion_reg(y0,ys)\n",
    "            #target_mse=criterion_reg(y1,yt)\n",
    "\n",
    "            #combined loss\n",
    "            combined_loss=regression_loss(concat_true,concat_pred)\n",
    "            #print('Training loss: ',combined_loss.item())\n",
    "            # backward propagation\n",
    "            combined_loss.backward()\n",
    "\n",
    "            # optimize\n",
    "            optimizer.step()\n",
    "        #train_loss.append(loss_cal(X_train,y_train,net))\n",
    "        #val_loss.append(loss_cal(X_val,y_val,net))\n",
    "        \n",
    "        # Add prune mechanism\n",
    "        #trial.report(accuracy, ep)\n",
    "\n",
    "        #if trial.should_prune():\n",
    "        #   raise optuna.exceptions.TrialPruned()\n",
    "            \n",
    "    return cal_pehe(X_val,y_val,model),model\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "19615b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-28 09:49:25,567]\u001b[0m A new study created in memory with name: no-name-5402d137-0434-44d4-a2e7-dc961460991e\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2023-02-28 09:49:27,220]\u001b[0m Trial 0 finished with value: 0.9412173628807068 and parameters: {'learning_rate': 9.929025330113483e-05, 'optimizer': 'SGD', 'batch_size': 226, 'RL11': 371, 'RL21': 196, 'RL32': 91, 'RG012': 326, 'RG022': 461, 'RG112': 32, 'RG122': 435}. Best is trial 0 with value: 0.9412173628807068.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2023-02-28 09:49:31,146]\u001b[0m Trial 1 finished with value: 0.9045663475990295 and parameters: {'learning_rate': 7.530251425944107e-05, 'optimizer': 'SGD', 'batch_size': 13, 'RL11': 485, 'RL21': 176, 'RL32': 353, 'RG012': 420, 'RG022': 35, 'RG112': 447, 'RG122': 114}. Best is trial 1 with value: 0.9045663475990295.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2023-02-28 09:49:34,220]\u001b[0m Trial 2 finished with value: 1.545295238494873 and parameters: {'learning_rate': 0.0007780026947085627, 'optimizer': 'Adam', 'batch_size': 28, 'RL11': 254, 'RL21': 394, 'RL32': 204, 'RG012': 75, 'RG022': 286, 'RG112': 94, 'RG122': 196}. Best is trial 1 with value: 0.9045663475990295.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2023-02-28 09:49:37,730]\u001b[0m Trial 3 finished with value: 0.8294389247894287 and parameters: {'learning_rate': 7.161264815157084e-05, 'optimizer': 'Adam', 'batch_size': 241, 'RL11': 337, 'RL21': 462, 'RL32': 478, 'RG012': 414, 'RG022': 156, 'RG112': 377, 'RG122': 398}. Best is trial 3 with value: 0.8294389247894287.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:49:40,178]\u001b[0m Trial 4 failed with parameters: {'learning_rate': 0.0016734669410608221, 'optimizer': 'SGD', 'batch_size': 180, 'RL11': 67, 'RL21': 389, 'RL32': 498, 'RG012': 355, 'RG022': 304, 'RG112': 488, 'RG122': 376} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:49:40,179]\u001b[0m Trial 4 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2023-02-28 09:49:41,800]\u001b[0m Trial 5 finished with value: 1.2042009830474854 and parameters: {'learning_rate': 0.002663555557121659, 'optimizer': 'Adam', 'batch_size': 255, 'RL11': 190, 'RL21': 70, 'RL32': 214, 'RG012': 198, 'RG022': 18, 'RG112': 192, 'RG122': 175}. Best is trial 3 with value: 0.8294389247894287.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2023-02-28 09:49:43,687]\u001b[0m Trial 6 finished with value: 0.728326141834259 and parameters: {'learning_rate': 0.0004766701346011841, 'optimizer': 'Adam', 'batch_size': 234, 'RL11': 29, 'RL21': 252, 'RL32': 122, 'RG012': 338, 'RG022': 504, 'RG112': 165, 'RG122': 50}. Best is trial 6 with value: 0.728326141834259.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2023-02-28 09:49:47,024]\u001b[0m Trial 7 finished with value: 542.0099487304688 and parameters: {'learning_rate': 0.07242528226315062, 'optimizer': 'Adam', 'batch_size': 159, 'RL11': 378, 'RL21': 270, 'RL32': 319, 'RG012': 504, 'RG022': 344, 'RG112': 243, 'RG122': 264}. Best is trial 6 with value: 0.728326141834259.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2023-02-28 09:49:50,054]\u001b[0m Trial 8 finished with value: 1.9021191596984863 and parameters: {'learning_rate': 1.296529521303207e-05, 'optimizer': 'Adam', 'batch_size': 40, 'RL11': 373, 'RL21': 476, 'RL32': 62, 'RG012': 25, 'RG022': 194, 'RG112': 452, 'RG122': 428}. Best is trial 6 with value: 0.728326141834259.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:49:52,088]\u001b[0m Trial 9 failed with parameters: {'learning_rate': 0.012496430070978573, 'optimizer': 'SGD', 'batch_size': 72, 'RL11': 360, 'RL21': 310, 'RL32': 254, 'RG012': 76, 'RG022': 40, 'RG112': 324, 'RG122': 370} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:49:52,088]\u001b[0m Trial 9 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:49:53,924]\u001b[0m Trial 10 failed with parameters: {'learning_rate': 0.03596045817806215, 'optimizer': 'SGD', 'batch_size': 55, 'RL11': 380, 'RL21': 400, 'RL32': 114, 'RG012': 251, 'RG022': 498, 'RG112': 342, 'RG122': 331} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:49:53,924]\u001b[0m Trial 10 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2023-02-28 09:49:56,603]\u001b[0m Trial 11 finished with value: 1.433795690536499 and parameters: {'learning_rate': 0.007492885894975343, 'optimizer': 'Adam', 'batch_size': 42, 'RL11': 400, 'RL21': 254, 'RL32': 102, 'RG012': 238, 'RG022': 400, 'RG112': 146, 'RG122': 84}. Best is trial 6 with value: 0.728326141834259.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-02-28 09:49:58,548]\u001b[0m Trial 12 failed with parameters: {'learning_rate': 0.0032661967682390738, 'optimizer': 'SGD', 'batch_size': 170, 'RL11': 370, 'RL21': 198, 'RL32': 470, 'RG012': 381, 'RG022': 60, 'RG112': 309, 'RG122': 215} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:49:58,549]\u001b[0m Trial 12 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2023-02-28 09:50:01,727]\u001b[0m Trial 13 finished with value: 42.24101638793945 and parameters: {'learning_rate': 0.07984699173956449, 'optimizer': 'Adam', 'batch_size': 194, 'RL11': 423, 'RL21': 168, 'RL32': 414, 'RG012': 435, 'RG022': 230, 'RG112': 310, 'RG122': 63}. Best is trial 6 with value: 0.728326141834259.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:50:04,120]\u001b[0m Trial 14 failed with parameters: {'learning_rate': 0.0006060172874334604, 'optimizer': 'SGD', 'batch_size': 102, 'RL11': 31, 'RL21': 361, 'RL32': 20, 'RG012': 316, 'RG022': 498, 'RG112': 303, 'RG122': 309} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:50:04,121]\u001b[0m Trial 14 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:50:06,602]\u001b[0m Trial 15 failed with parameters: {'learning_rate': 0.0006970865330954458, 'optimizer': 'SGD', 'batch_size': 96, 'RL11': 42, 'RL21': 368, 'RL32': 177, 'RG012': 143, 'RG022': 505, 'RG112': 293, 'RG122': 284} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:50:06,602]\u001b[0m Trial 15 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:50:08,376]\u001b[0m Trial 16 failed with parameters: {'learning_rate': 0.0006250763319516207, 'optimizer': 'SGD', 'batch_size': 116, 'RL11': 27, 'RL21': 355, 'RL32': 149, 'RG012': 316, 'RG022': 456, 'RG112': 314, 'RG122': 25} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:50:08,376]\u001b[0m Trial 16 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:50:10,530]\u001b[0m Trial 17 failed with parameters: {'learning_rate': 0.0005317614677232557, 'optimizer': 'SGD', 'batch_size': 98, 'RL11': 18, 'RL21': 16, 'RL32': 173, 'RG012': 315, 'RG022': 505, 'RG112': 297, 'RG122': 25} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:50:10,530]\u001b[0m Trial 17 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:50:12,008]\u001b[0m Trial 18 failed with parameters: {'learning_rate': 0.0005326898357061402, 'optimizer': 'SGD', 'batch_size': 106, 'RL11': 34, 'RL21': 339, 'RL32': 20, 'RG012': 157, 'RG022': 457, 'RG112': 277, 'RG122': 22} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:50:12,008]\u001b[0m Trial 18 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:50:13,793]\u001b[0m Trial 19 failed with parameters: {'learning_rate': 0.0008381739795331885, 'optimizer': 'SGD', 'batch_size': 107, 'RL11': 30, 'RL21': 353, 'RL32': 155, 'RG012': 303, 'RG022': 491, 'RG112': 282, 'RG122': 27} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:50:13,794]\u001b[0m Trial 19 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:50:15,615]\u001b[0m Trial 20 failed with parameters: {'learning_rate': 0.0004969581265922806, 'optimizer': 'SGD', 'batch_size': 106, 'RL11': 22, 'RL21': 356, 'RL32': 169, 'RG012': 323, 'RG022': 499, 'RG112': 303, 'RG122': 327} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:50:15,616]\u001b[0m Trial 20 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:50:17,137]\u001b[0m Trial 21 failed with parameters: {'learning_rate': 0.0004764603393036989, 'optimizer': 'SGD', 'batch_size': 112, 'RL11': 28, 'RL21': 348, 'RL32': 20, 'RG012': 123, 'RG022': 509, 'RG112': 303, 'RG122': 21} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:50:17,138]\u001b[0m Trial 21 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:50:18,816]\u001b[0m Trial 22 failed with parameters: {'learning_rate': 0.00042060702257907054, 'optimizer': 'SGD', 'batch_size': 107, 'RL11': 23, 'RL21': 20, 'RL32': 161, 'RG012': 142, 'RG022': 505, 'RG112': 311, 'RG122': 304} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:50:18,816]\u001b[0m Trial 22 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:50:21,161]\u001b[0m Trial 23 failed with parameters: {'learning_rate': 0.0005142791411551016, 'optimizer': 'SGD', 'batch_size': 89, 'RL11': 22, 'RL21': 339, 'RL32': 151, 'RG012': 156, 'RG022': 505, 'RG112': 271, 'RG122': 323} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:50:21,162]\u001b[0m Trial 23 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-02-28 09:50:23,540]\u001b[0m Trial 24 failed with parameters: {'learning_rate': 0.0005865765148533919, 'optimizer': 'SGD', 'batch_size': 95, 'RL11': 25, 'RL21': 345, 'RL32': 173, 'RG012': 149, 'RG022': 499, 'RG112': 295, 'RG122': 323} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:50:23,541]\u001b[0m Trial 24 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:50:25,246]\u001b[0m Trial 25 failed with parameters: {'learning_rate': 0.0007904542976131076, 'optimizer': 'SGD', 'batch_size': 105, 'RL11': 82, 'RL21': 16, 'RL32': 175, 'RG012': 312, 'RG022': 460, 'RG112': 293, 'RG122': 19} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:50:25,247]\u001b[0m Trial 25 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:50:27,352]\u001b[0m Trial 26 failed with parameters: {'learning_rate': 0.0011319240855487266, 'optimizer': 'SGD', 'batch_size': 103, 'RL11': 20, 'RL21': 326, 'RL32': 17, 'RG012': 147, 'RG022': 512, 'RG112': 299, 'RG122': 318} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:50:27,352]\u001b[0m Trial 26 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:50:28,956]\u001b[0m Trial 27 failed with parameters: {'learning_rate': 0.0005797593276462658, 'optimizer': 'SGD', 'batch_size': 115, 'RL11': 21, 'RL21': 21, 'RL32': 189, 'RG012': 160, 'RG022': 465, 'RG112': 298, 'RG122': 18} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:50:28,956]\u001b[0m Trial 27 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:50:30,507]\u001b[0m Trial 28 failed with parameters: {'learning_rate': 0.00043904567098817935, 'optimizer': 'SGD', 'batch_size': 105, 'RL11': 28, 'RL21': 35, 'RL32': 164, 'RG012': 150, 'RG022': 512, 'RG112': 305, 'RG122': 28} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:50:30,508]\u001b[0m Trial 28 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:50:32,625]\u001b[0m Trial 29 failed with parameters: {'learning_rate': 0.0006124705998378465, 'optimizer': 'SGD', 'batch_size': 101, 'RL11': 23, 'RL21': 36, 'RL32': 18, 'RG012': 150, 'RG022': 471, 'RG112': 300, 'RG122': 18} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:50:32,625]\u001b[0m Trial 29 failed with value nan.\u001b[0m\n",
      "\u001b[32m[I 2023-02-28 09:50:34,689]\u001b[0m A new study created in memory with name: no-name-f23a7c8b-d603-455d-82a7-06c13cf24583\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:50:36,829]\u001b[0m Trial 0 failed with parameters: {'learning_rate': 0.0012024144671617504, 'optimizer': 'SGD', 'batch_size': 225, 'RL11': 105, 'RL21': 486, 'RL32': 323, 'RG012': 350, 'RG022': 365, 'RG112': 202, 'RG122': 198} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:50:36,830]\u001b[0m Trial 0 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2023-02-28 09:50:40,198]\u001b[0m Trial 1 finished with value: 1.309417963027954 and parameters: {'learning_rate': 0.014439263278839652, 'optimizer': 'Adam', 'batch_size': 68, 'RL11': 212, 'RL21': 224, 'RL32': 370, 'RG012': 140, 'RG022': 29, 'RG112': 285, 'RG122': 381}. Best is trial 1 with value: 1.309417963027954.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:50:42,079]\u001b[0m Trial 2 failed with parameters: {'learning_rate': 0.05052511510283731, 'optimizer': 'SGD', 'batch_size': 59, 'RL11': 418, 'RL21': 277, 'RL32': 133, 'RG012': 69, 'RG022': 232, 'RG112': 481, 'RG122': 509} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:50:42,079]\u001b[0m Trial 2 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2023-02-28 09:50:44,053]\u001b[0m Trial 3 finished with value: 0.6772018671035767 and parameters: {'learning_rate': 0.0002946750037518271, 'optimizer': 'Adam', 'batch_size': 104, 'RL11': 34, 'RL21': 299, 'RL32': 71, 'RG012': 403, 'RG022': 396, 'RG112': 384, 'RG122': 204}. Best is trial 3 with value: 0.6772018671035767.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2023-02-28 09:50:46,147]\u001b[0m Trial 4 finished with value: 1.6721372604370117 and parameters: {'learning_rate': 0.011261858838423908, 'optimizer': 'Adam', 'batch_size': 188, 'RL11': 453, 'RL21': 16, 'RL32': 252, 'RG012': 385, 'RG022': 134, 'RG112': 332, 'RG122': 395}. Best is trial 3 with value: 0.6772018671035767.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2023-02-28 09:50:47,864]\u001b[0m Trial 5 finished with value: 0.683114230632782 and parameters: {'learning_rate': 4.646353310674187e-05, 'optimizer': 'SGD', 'batch_size': 149, 'RL11': 230, 'RL21': 350, 'RL32': 188, 'RG012': 460, 'RG022': 399, 'RG112': 90, 'RG122': 210}. Best is trial 3 with value: 0.6772018671035767.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-02-28 09:50:50,595]\u001b[0m Trial 6 failed with parameters: {'learning_rate': 0.034008976125369524, 'optimizer': 'SGD', 'batch_size': 28, 'RL11': 37, 'RL21': 345, 'RL32': 375, 'RG012': 275, 'RG022': 475, 'RG112': 249, 'RG122': 504} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:50:50,596]\u001b[0m Trial 6 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:50:53,231]\u001b[0m Trial 7 failed with parameters: {'learning_rate': 0.037750369982401256, 'optimizer': 'SGD', 'batch_size': 252, 'RL11': 169, 'RL21': 439, 'RL32': 436, 'RG012': 392, 'RG022': 478, 'RG112': 90, 'RG122': 399} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:50:53,232]\u001b[0m Trial 7 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:50:55,719]\u001b[0m Trial 8 failed with parameters: {'learning_rate': 0.0017058266134450002, 'optimizer': 'SGD', 'batch_size': 237, 'RL11': 370, 'RL21': 490, 'RL32': 317, 'RG012': 447, 'RG022': 343, 'RG112': 99, 'RG122': 255} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:50:55,719]\u001b[0m Trial 8 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2023-02-28 09:50:57,476]\u001b[0m Trial 9 finished with value: 0.6641115546226501 and parameters: {'learning_rate': 0.00021934559370376196, 'optimizer': 'Adam', 'batch_size': 187, 'RL11': 108, 'RL21': 39, 'RL32': 494, 'RG012': 135, 'RG022': 277, 'RG112': 160, 'RG122': 160}. Best is trial 9 with value: 0.6641115546226501.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:50:59,534]\u001b[0m Trial 10 failed with parameters: {'learning_rate': 0.06516517153193031, 'optimizer': 'SGD', 'batch_size': 244, 'RL11': 462, 'RL21': 496, 'RL32': 240, 'RG012': 35, 'RG022': 280, 'RG112': 223, 'RG122': 328} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:50:59,534]\u001b[0m Trial 10 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2023-02-28 09:51:01,726]\u001b[0m Trial 11 finished with value: 1.8368686437606812 and parameters: {'learning_rate': 0.001685484105949144, 'optimizer': 'Adam', 'batch_size': 112, 'RL11': 319, 'RL21': 327, 'RL32': 98, 'RG012': 432, 'RG022': 336, 'RG112': 221, 'RG122': 352}. Best is trial 9 with value: 0.6641115546226501.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2023-02-28 09:51:04,523]\u001b[0m Trial 12 finished with value: 0.625324010848999 and parameters: {'learning_rate': 3.4729019855877446e-05, 'optimizer': 'SGD', 'batch_size': 72, 'RL11': 419, 'RL21': 344, 'RL32': 311, 'RG012': 112, 'RG022': 483, 'RG112': 242, 'RG122': 236}. Best is trial 12 with value: 0.625324010848999.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2023-02-28 09:51:06,528]\u001b[0m Trial 13 finished with value: 0.6204575300216675 and parameters: {'learning_rate': 0.00025739740828551084, 'optimizer': 'Adam', 'batch_size': 123, 'RL11': 168, 'RL21': 402, 'RL32': 152, 'RG012': 319, 'RG022': 200, 'RG112': 272, 'RG122': 196}. Best is trial 13 with value: 0.6204575300216675.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2023-02-28 09:51:08,665]\u001b[0m Trial 14 finished with value: 0.667290210723877 and parameters: {'learning_rate': 0.0006637794953857928, 'optimizer': 'Adam', 'batch_size': 135, 'RL11': 23, 'RL21': 392, 'RL32': 49, 'RG012': 499, 'RG022': 470, 'RG112': 238, 'RG122': 66}. Best is trial 13 with value: 0.6204575300216675.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2023-02-28 09:51:11,550]\u001b[0m Trial 15 finished with value: 0.6977365016937256 and parameters: {'learning_rate': 8.15698467774922e-05, 'optimizer': 'Adam', 'batch_size': 31, 'RL11': 29, 'RL21': 246, 'RL32': 313, 'RG012': 130, 'RG022': 100, 'RG112': 509, 'RG122': 308}. Best is trial 13 with value: 0.6204575300216675.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2023-02-28 09:51:13,264]\u001b[0m Trial 16 finished with value: 0.8045254349708557 and parameters: {'learning_rate': 1.5644486093959102e-05, 'optimizer': 'SGD', 'batch_size': 219, 'RL11': 155, 'RL21': 508, 'RL32': 149, 'RG012': 292, 'RG022': 213, 'RG112': 430, 'RG122': 25}. Best is trial 13 with value: 0.6204575300216675.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2023-02-28 09:51:16,907]\u001b[0m Trial 17 finished with value: 0.8734386563301086 and parameters: {'learning_rate': 1.580631996177762e-05, 'optimizer': 'SGD', 'batch_size': 15, 'RL11': 370, 'RL21': 458, 'RL32': 390, 'RG012': 35, 'RG022': 508, 'RG112': 33, 'RG122': 146}. Best is trial 13 with value: 0.6204575300216675.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2023-02-28 09:51:19,064]\u001b[0m Trial 18 finished with value: 0.7610596418380737 and parameters: {'learning_rate': 9.930980518038101e-05, 'optimizer': 'SGD', 'batch_size': 67, 'RL11': 507, 'RL21': 173, 'RL32': 239, 'RG012': 272, 'RG022': 215, 'RG112': 166, 'RG122': 266}. Best is trial 13 with value: 0.6204575300216675.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[32m[I 2023-02-28 09:51:21,699]\u001b[0m Trial 19 finished with value: 1.087802767753601 and parameters: {'learning_rate': 1.0077577279875214e-05, 'optimizer': 'SGD', 'batch_size': 83, 'RL11': 353, 'RL21': 404, 'RL32': 157, 'RG012': 201, 'RG022': 285, 'RG112': 314, 'RG122': 485}. Best is trial 13 with value: 0.6204575300216675.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:51:23,657]\u001b[0m Trial 20 failed with parameters: {'learning_rate': 0.0006765829958730669, 'optimizer': 'SGD', 'batch_size': 48, 'RL11': 291, 'RL21': 430, 'RL32': 321, 'RG012': 322, 'RG022': 159, 'RG112': 177, 'RG122': 93} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:51:23,658]\u001b[0m Trial 20 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:51:25,407]\u001b[0m Trial 21 failed with parameters: {'learning_rate': 0.0014955664161160013, 'optimizer': 'SGD', 'batch_size': 163, 'RL11': 291, 'RL21': 151, 'RL32': 333, 'RG012': 338, 'RG022': 175, 'RG112': 177, 'RG122': 124} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:51:25,407]\u001b[0m Trial 21 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:51:28,222]\u001b[0m Trial 22 failed with parameters: {'learning_rate': 0.07659081443342546, 'optimizer': 'SGD', 'batch_size': 162, 'RL11': 426, 'RL21': 449, 'RL32': 328, 'RG012': 348, 'RG022': 173, 'RG112': 183, 'RG122': 123} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:51:28,222]\u001b[0m Trial 22 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:51:30,478]\u001b[0m Trial 23 failed with parameters: {'learning_rate': 0.0012738680272562238, 'optimizer': 'SGD', 'batch_size': 161, 'RL11': 280, 'RL21': 151, 'RL32': 314, 'RG012': 347, 'RG022': 145, 'RG112': 178, 'RG122': 106} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:51:30,479]\u001b[0m Trial 23 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:51:33,286]\u001b[0m Trial 24 failed with parameters: {'learning_rate': 0.0011609547437734596, 'optimizer': 'SGD', 'batch_size': 162, 'RL11': 432, 'RL21': 430, 'RL32': 329, 'RG012': 334, 'RG022': 178, 'RG112': 168, 'RG122': 106} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:51:33,287]\u001b[0m Trial 24 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:51:35,791]\u001b[0m Trial 25 failed with parameters: {'learning_rate': 0.0016438565753895296, 'optimizer': 'SGD', 'batch_size': 158, 'RL11': 285, 'RL21': 437, 'RL32': 317, 'RG012': 336, 'RG022': 152, 'RG112': 183, 'RG122': 107} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:51:35,791]\u001b[0m Trial 25 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:51:38,452]\u001b[0m Trial 26 failed with parameters: {'learning_rate': 0.09663067251240164, 'optimizer': 'SGD', 'batch_size': 160, 'RL11': 431, 'RL21': 433, 'RL32': 328, 'RG012': 328, 'RG022': 155, 'RG112': 167, 'RG122': 99} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:51:38,452]\u001b[0m Trial 26 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:51:40,761]\u001b[0m Trial 27 failed with parameters: {'learning_rate': 0.001639388126653917, 'optimizer': 'SGD', 'batch_size': 256, 'RL11': 286, 'RL21': 437, 'RL32': 333, 'RG012': 342, 'RG022': 169, 'RG112': 204, 'RG122': 102} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:51:40,762]\u001b[0m Trial 27 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:51:43,261]\u001b[0m Trial 28 failed with parameters: {'learning_rate': 0.09165702721185648, 'optimizer': 'SGD', 'batch_size': 158, 'RL11': 271, 'RL21': 418, 'RL32': 334, 'RG012': 342, 'RG022': 167, 'RG112': 185, 'RG122': 106} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:51:43,262]\u001b[0m Trial 28 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_6549/1595419454.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
      "\u001b[33m[W 2023-02-28 09:51:44,907]\u001b[0m Trial 29 failed with parameters: {'learning_rate': 0.09663139230036782, 'optimizer': 'SGD', 'batch_size': 47, 'RL11': 287, 'RL21': 153, 'RL32': 311, 'RG012': 331, 'RG022': 167, 'RG112': 196, 'RG122': 117} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-02-28 09:51:44,908]\u001b[0m Trial 29 failed with value nan.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pehe_total=[]\n",
    "for i in range(1,101):\n",
    "    func = lambda trial: objective(trial, i)\n",
    "    study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler())\n",
    "    study.optimize(func, n_trials=30)\n",
    "    best_trial = study.best_trial\n",
    "    best_model=TarNet(study.best_trial.params)\n",
    "    best_val,model=train_evaluate(study.best_trial.params, best_model, study.best_trial,i)\n",
    "    data,y=get_data('test',i)\n",
    "    pehe=cal_pehe(data,y,model)\n",
    "\n",
    "    pehe_total.append(pehe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aea84909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5950204730033875, 0.6529917120933533]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pehe_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb8e4efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pehe_total\n",
    "#for key, value in best_trial.params.items():\n",
    "#    print(\"{}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f0b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ate_pred=torch.mean(cate_pred)\n",
    "#print(\"Estimated ATE (True is 4):\", ate_pred.detach().numpy(),'\\n\\n')\n",
    "\n",
    "#print(\"Individualized CATE Estimates: BLUE\")\n",
    "#print(pd.Series(cate_pred.detach().numpy()).plot.kde(color='blue'))\n",
    "#print(\"Individualized CATE True: Green\")\n",
    "#print(pd.Series(cate_true.detach().numpy()).plot.kde(color='green'))\n",
    "\n",
    "#print(\"\\nError CATE Estimates: RED\")\n",
    "#print(pd.Series(cate_pred.detach().numpy()-cate_true.detach().numpy()).plot.kde(color='red'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
