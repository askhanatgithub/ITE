{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d03fc716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f22c4234730>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from geomloss import SamplesLoss\n",
    "from torch.autograd import Function\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.functional import normalize\n",
    "#from torchmetrics.classification import BinaryAccuracy\n",
    "from torchmetrics.classification import BinaryF1Score\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d198f963",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y).type(torch.LongTensor)\n",
    "        self.len = self.X.shape[0]\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "   \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baec050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_type,file_num):\n",
    "\n",
    "    if(data_type=='train'):\n",
    "        data=pd.read_csv(f\"Dataset/IHDP_a/ihdp_npci_train_{file_num}.csv\")\n",
    "    else:\n",
    "        data = pd.read_csv(f\"Dataset/IHDP_a/ihdp_npci_test_{file_num}.csv\")\n",
    "\n",
    "    x_data=pd.concat([data.iloc[:,0], data.iloc[:, 1:30]], axis = 1)\n",
    "    #x_data=data.iloc[:, 5:30]\n",
    "    y_data=data.iloc[:, 0]\n",
    "    return x_data,y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26153848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(x_data,y_data,batch_size):\n",
    "\n",
    "    x_train_sr=x_data[x_data['treatment']==0]\n",
    "    y_train_sr=y_data[x_data['treatment']==0]\n",
    "    x_train_tr=x_data[x_data['treatment']==1]\n",
    "    y_train_tr=y_data[x_data['treatment']==1]\n",
    "\n",
    "\n",
    "    train_data_sr = Data(np.array(x_train_sr), np.array(y_train_sr))\n",
    "    train_dataloader_sr = DataLoader(dataset=train_data_sr, batch_size=batch_size)\n",
    "\n",
    "    train_data_tr = Data(np.array(x_train_tr), np.array(y_train_tr))\n",
    "    train_dataloader_tr = DataLoader(dataset=train_data_tr, batch_size=batch_size)\n",
    "\n",
    "\n",
    "    return train_dataloader_sr, train_dataloader_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7539131",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim=25\n",
    "hidden_layers=50\n",
    "output_dim=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbc3df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Discriminator, self).__init__()\n",
    "    self.linear1 = nn.Linear(input_dim, hidden_layers)\n",
    "    self.linear2 = nn.Linear(hidden_layers, output_dim)\n",
    "  def forward(self, x):\n",
    "    x = torch.sigmoid(self.linear1(x))\n",
    "    x = self.linear2(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40b23ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5064d2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=200\n",
    "batch_size=16\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.SGD(clf.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8852ba86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,     8] loss: 0.00278\n",
      "[3,     8] loss: 0.00276\n",
      "[4,     8] loss: 0.00274\n",
      "[5,     8] loss: 0.00272\n",
      "[6,     8] loss: 0.00270\n",
      "[7,     8] loss: 0.00268\n",
      "[8,     8] loss: 0.00266\n",
      "[9,     8] loss: 0.00264\n",
      "[10,     8] loss: 0.00262\n",
      "[11,     8] loss: 0.00260\n",
      "[12,     8] loss: 0.00258\n",
      "[13,     8] loss: 0.00255\n",
      "[14,     8] loss: 0.00253\n",
      "[15,     8] loss: 0.00250\n",
      "[16,     8] loss: 0.00247\n",
      "[17,     8] loss: 0.00245\n",
      "[18,     8] loss: 0.00242\n",
      "[19,     8] loss: 0.00239\n",
      "[20,     8] loss: 0.00236\n",
      "[21,     8] loss: 0.00233\n",
      "[22,     8] loss: 0.00230\n",
      "[23,     8] loss: 0.00227\n",
      "[24,     8] loss: 0.00224\n",
      "[25,     8] loss: 0.00221\n",
      "[26,     8] loss: 0.00218\n",
      "[27,     8] loss: 0.00215\n",
      "[28,     8] loss: 0.00212\n",
      "[29,     8] loss: 0.00209\n",
      "[30,     8] loss: 0.00206\n",
      "[31,     8] loss: 0.00204\n",
      "[32,     8] loss: 0.00201\n",
      "[33,     8] loss: 0.00198\n",
      "[34,     8] loss: 0.00195\n",
      "[35,     8] loss: 0.00193\n",
      "[36,     8] loss: 0.00190\n",
      "[37,     8] loss: 0.00187\n",
      "[38,     8] loss: 0.00185\n",
      "[39,     8] loss: 0.00182\n",
      "[40,     8] loss: 0.00180\n",
      "[41,     8] loss: 0.00178\n",
      "[42,     8] loss: 0.00175\n",
      "[43,     8] loss: 0.00173\n",
      "[44,     8] loss: 0.00171\n",
      "[45,     8] loss: 0.00168\n",
      "[46,     8] loss: 0.00166\n",
      "[47,     8] loss: 0.00164\n",
      "[48,     8] loss: 0.00162\n",
      "[49,     8] loss: 0.00160\n",
      "[50,     8] loss: 0.00158\n",
      "[51,     8] loss: 0.00157\n",
      "[52,     8] loss: 0.00155\n",
      "[53,     8] loss: 0.00153\n",
      "[54,     8] loss: 0.00151\n",
      "[55,     8] loss: 0.00150\n",
      "[56,     8] loss: 0.00148\n",
      "[57,     8] loss: 0.00147\n",
      "[58,     8] loss: 0.00146\n",
      "[59,     8] loss: 0.00144\n",
      "[60,     8] loss: 0.00143\n",
      "[61,     8] loss: 0.00142\n",
      "[62,     8] loss: 0.00141\n",
      "[63,     8] loss: 0.00140\n",
      "[64,     8] loss: 0.00139\n",
      "[65,     8] loss: 0.00138\n",
      "[66,     8] loss: 0.00137\n",
      "[67,     8] loss: 0.00136\n",
      "[68,     8] loss: 0.00135\n",
      "[69,     8] loss: 0.00134\n",
      "[70,     8] loss: 0.00133\n",
      "[71,     8] loss: 0.00132\n",
      "[72,     8] loss: 0.00132\n",
      "[73,     8] loss: 0.00131\n",
      "[74,     8] loss: 0.00130\n",
      "[75,     8] loss: 0.00130\n",
      "[76,     8] loss: 0.00129\n",
      "[77,     8] loss: 0.00129\n",
      "[78,     8] loss: 0.00128\n",
      "[79,     8] loss: 0.00127\n",
      "[80,     8] loss: 0.00127\n",
      "[81,     8] loss: 0.00126\n",
      "[82,     8] loss: 0.00126\n",
      "[83,     8] loss: 0.00126\n",
      "[84,     8] loss: 0.00125\n",
      "[85,     8] loss: 0.00125\n",
      "[86,     8] loss: 0.00124\n",
      "[87,     8] loss: 0.00124\n",
      "[88,     8] loss: 0.00124\n",
      "[89,     8] loss: 0.00123\n",
      "[90,     8] loss: 0.00123\n",
      "[91,     8] loss: 0.00123\n",
      "[92,     8] loss: 0.00122\n",
      "[93,     8] loss: 0.00122\n",
      "[94,     8] loss: 0.00122\n",
      "[95,     8] loss: 0.00121\n",
      "[96,     8] loss: 0.00121\n",
      "[97,     8] loss: 0.00121\n",
      "[98,     8] loss: 0.00121\n",
      "[99,     8] loss: 0.00120\n",
      "[100,     8] loss: 0.00120\n",
      "[101,     8] loss: 0.00120\n",
      "[102,     8] loss: 0.00120\n",
      "[103,     8] loss: 0.00120\n",
      "[104,     8] loss: 0.00119\n",
      "[105,     8] loss: 0.00119\n",
      "[106,     8] loss: 0.00119\n",
      "[107,     8] loss: 0.00119\n",
      "[108,     8] loss: 0.00119\n",
      "[109,     8] loss: 0.00118\n",
      "[110,     8] loss: 0.00118\n",
      "[111,     8] loss: 0.00118\n",
      "[112,     8] loss: 0.00118\n",
      "[113,     8] loss: 0.00118\n",
      "[114,     8] loss: 0.00117\n",
      "[115,     8] loss: 0.00117\n",
      "[116,     8] loss: 0.00117\n",
      "[117,     8] loss: 0.00117\n",
      "[118,     8] loss: 0.00117\n",
      "[119,     8] loss: 0.00117\n",
      "[120,     8] loss: 0.00117\n",
      "[121,     8] loss: 0.00116\n",
      "[122,     8] loss: 0.00116\n",
      "[123,     8] loss: 0.00116\n",
      "[124,     8] loss: 0.00116\n",
      "[125,     8] loss: 0.00116\n",
      "[126,     8] loss: 0.00116\n",
      "[127,     8] loss: 0.00116\n",
      "[128,     8] loss: 0.00116\n",
      "[129,     8] loss: 0.00115\n",
      "[130,     8] loss: 0.00115\n",
      "[131,     8] loss: 0.00115\n",
      "[132,     8] loss: 0.00115\n",
      "[133,     8] loss: 0.00115\n",
      "[134,     8] loss: 0.00115\n",
      "[135,     8] loss: 0.00115\n",
      "[136,     8] loss: 0.00115\n",
      "[137,     8] loss: 0.00115\n",
      "[138,     8] loss: 0.00115\n",
      "[139,     8] loss: 0.00114\n",
      "[140,     8] loss: 0.00114\n",
      "[141,     8] loss: 0.00114\n",
      "[142,     8] loss: 0.00114\n",
      "[143,     8] loss: 0.00114\n",
      "[144,     8] loss: 0.00114\n",
      "[145,     8] loss: 0.00114\n",
      "[146,     8] loss: 0.00114\n",
      "[147,     8] loss: 0.00114\n",
      "[148,     8] loss: 0.00114\n",
      "[149,     8] loss: 0.00114\n",
      "[150,     8] loss: 0.00113\n",
      "[151,     8] loss: 0.00113\n",
      "[152,     8] loss: 0.00113\n",
      "[153,     8] loss: 0.00113\n",
      "[154,     8] loss: 0.00113\n",
      "[155,     8] loss: 0.00113\n",
      "[156,     8] loss: 0.00113\n",
      "[157,     8] loss: 0.00113\n",
      "[158,     8] loss: 0.00113\n",
      "[159,     8] loss: 0.00113\n",
      "[160,     8] loss: 0.00113\n",
      "[161,     8] loss: 0.00113\n",
      "[162,     8] loss: 0.00113\n",
      "[163,     8] loss: 0.00112\n",
      "[164,     8] loss: 0.00112\n",
      "[165,     8] loss: 0.00112\n",
      "[166,     8] loss: 0.00112\n",
      "[167,     8] loss: 0.00112\n",
      "[168,     8] loss: 0.00112\n",
      "[169,     8] loss: 0.00112\n",
      "[170,     8] loss: 0.00112\n",
      "[171,     8] loss: 0.00112\n",
      "[172,     8] loss: 0.00112\n",
      "[173,     8] loss: 0.00112\n",
      "[174,     8] loss: 0.00112\n",
      "[175,     8] loss: 0.00112\n",
      "[176,     8] loss: 0.00112\n",
      "[177,     8] loss: 0.00112\n",
      "[178,     8] loss: 0.00112\n",
      "[179,     8] loss: 0.00111\n",
      "[180,     8] loss: 0.00111\n",
      "[181,     8] loss: 0.00111\n",
      "[182,     8] loss: 0.00111\n",
      "[183,     8] loss: 0.00111\n",
      "[184,     8] loss: 0.00111\n",
      "[185,     8] loss: 0.00111\n",
      "[186,     8] loss: 0.00111\n",
      "[187,     8] loss: 0.00111\n",
      "[188,     8] loss: 0.00111\n",
      "[189,     8] loss: 0.00111\n",
      "[190,     8] loss: 0.00111\n",
      "[191,     8] loss: 0.00111\n",
      "[192,     8] loss: 0.00111\n",
      "[193,     8] loss: 0.00111\n",
      "[194,     8] loss: 0.00111\n",
      "[195,     8] loss: 0.00110\n",
      "[196,     8] loss: 0.00110\n",
      "[197,     8] loss: 0.00110\n",
      "[198,     8] loss: 0.00110\n",
      "[199,     8] loss: 0.00110\n",
      "[200,     8] loss: 0.00110\n",
      "[201,     8] loss: 0.00110\n"
     ]
    }
   ],
   "source": [
    "pehe_lo = []\n",
    "domain_lo=[]\n",
    "s_reg_lo=[]\n",
    "t_reg_lo=[]\n",
    "d_accu=[]\n",
    "metric=BinaryF1Score()\n",
    "num_files=45\n",
    "for nf in range(44,num_files):\n",
    "    x_data,y_data=get_data('train',nf)\n",
    "\n",
    "    #optimizer3 = optim.SGD(Network.parameters(),lr=0.001,momentum=1e-8)\n",
    "    optimizer = torch.optim.SGD(clf.parameters(), lr=0.1)\n",
    "\n",
    "    for ep in range(1,epochs+1 ):\n",
    "        s_reg=0\n",
    "        t_reg=0\n",
    "        dl=0\n",
    "        peh=0\n",
    "        running_loss = 0.0\n",
    "        train_dataloader_sr, train_dataloader_tr=get_dataloader(x_data,y_data,batch_size)\n",
    "\n",
    "        for batch_idx, (train_source_data, train_target_data) in enumerate(zip(train_dataloader_sr, train_dataloader_tr)):\n",
    "            xs,ys=train_source_data\n",
    "            xt,yt=train_target_data\n",
    "            xs_train=xs[:,5:30]\n",
    "            xt_train=xt[:,5:30]\n",
    "            inputs=torch.cat((xs_train,xt_train),0)\n",
    "            labels=torch.cat((ys,yt),0)\n",
    "            # set optimizer to zero grad to remove previous epoch gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward propagation\n",
    "            outputs = clf(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # backward propagation\n",
    "            loss.backward()\n",
    "            # optimize\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "          # display statistics\n",
    "        print(f'[{ep + 1}, {batch_idx + 1:5d}] loss: {running_loss / 2000:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bcb5bef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.923\n",
      "Accuracy:  93\n"
     ]
    }
   ],
   "source": [
    "metric=BinaryF1Score()\n",
    "x_data,y_data=get_data('test',44)\n",
    "test_dataloader_sr, test_dataloader_tr=get_dataloader(x_data,y_data,batch_size)\n",
    "correct, total = 0, 0\n",
    "# no need to calculate gradients during inferenSce\n",
    "with torch.no_grad():\n",
    "  for batch_idx, (test_source_data, test_target_data) in enumerate(zip(test_dataloader_sr, test_dataloader_tr)):\n",
    "    xs,ys=test_source_data\n",
    "    xt,yt=test_target_data\n",
    "    xs_test=xs[:,5:30]\n",
    "    xt_test=xt[:,5:30]\n",
    "    inputs=torch.cat((xs_test,xt_test),0)\n",
    "    labels=torch.cat((ys,yt),0)\n",
    "    #inputs, labels = data\n",
    "    # calculate output by running through the network\n",
    "    outputs = clf(inputs)\n",
    "    # get the predictions\n",
    "    __, predicted = torch.max(outputs.data, 1)\n",
    "    # update results\n",
    "    total += labels.size(0)\n",
    "    print('F1 score: ',round(metric(predicted,labels).item(),3))\n",
    "    correct += (predicted == labels).sum().item()\n",
    "print('Accuracy: ',100 * correct // total )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "706f7766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([29])\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
