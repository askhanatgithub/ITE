{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "52542919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb2b3177e90>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from geomloss import SamplesLoss\n",
    "from torch.autograd import Function\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.functional import normalize\n",
    "#from torchmetrics.classification import BinaryAccuracy\n",
    "from torchmetrics.classification import BinaryF1Score\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e50bd733",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TarNet(nn.Module):\n",
    "    def __init__(self,params):\n",
    "        super(TarNet, self).__init__()\n",
    "        self.encoder1 = nn.Linear(25, params['RL11'])\n",
    "        self.encoder2 = nn.Linear(params['RL11'], params['RL21'])\n",
    "        self.encoder3 = nn.Linear(params['RL21'], params['RL32'])\n",
    "\n",
    "        self.regressor1_y0 = nn.Sequential(\n",
    "            nn.Linear(params['RL32'], params['RG012']),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=.01),\n",
    "        )\n",
    "        self.regressor2_y0 = nn.Sequential(\n",
    "            nn.Linear(params['RG012'], params['RG022']),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=.01),\n",
    "        )\n",
    "        self.regressorO_y0 = nn.Linear(params['RG022'], 1)\n",
    "\n",
    "        self.regressor1_y1 = nn.Sequential(\n",
    "            nn.Linear(params['RL32'], params['RG112']),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=.01),\n",
    "        )\n",
    "        self.regressor2_y1 = nn.Sequential(\n",
    "            nn.Linear(params['RG112'], params['RG122']),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=.01),\n",
    "        )\n",
    "        self.regressorO_y1 = nn.Linear(params['RG122'], 1)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = nn.functional.elu(self.encoder1(inputs))\n",
    "        x = nn.functional.elu(self.encoder2(x))\n",
    "        phi = nn.functional.elu(self.encoder3(x))\n",
    "\n",
    "        out_y0 = self.regressor1_y0(phi)\n",
    "        out_y0 = self.regressor2_y0(out_y0)\n",
    "        y0 = self.regressorO_y0(out_y0)\n",
    "\n",
    "        out_y1 = self.regressor1_y1(phi)\n",
    "        out_y1 = self.regressor2_y1(out_y1)\n",
    "        y1 = self.regressorO_y1(out_y1)\n",
    "\n",
    "        concat = torch.cat((y0, y1), 1)\n",
    "        return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "70c58121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial,i):\n",
    "\n",
    "    params = {\n",
    "          'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
    "          'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\"]),\n",
    "          'batch_size':trial.suggest_int('batch_size', 8, 256),\n",
    "          'RL11':trial.suggest_int('RL11', 16, 512),\n",
    "          'RL21': trial.suggest_int('RL21', 16, 512),\n",
    "          'RL32': trial.suggest_int('RL32', 16, 512),\n",
    "          'RG012':trial.suggest_int('RG012', 16, 512),\n",
    "        'RG022':trial.suggest_int('RG022', 16, 512),\n",
    "        'RG112':trial.suggest_int('RG112', 16, 512),\n",
    "        'RG122':trial.suggest_int('RG122', 16, 512),\n",
    "          \n",
    "          }\n",
    "\n",
    "    model = TarNet(params)\n",
    "\n",
    "    pehe,model= train_evaluate(params, model, trial,i)\n",
    "\n",
    "    return pehe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "48800d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y.astype(np.float32))\n",
    "        self.len = self.X.shape[0]\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "   \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d80cf340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_type,file_num):\n",
    "\n",
    "    if(data_type=='train'):\n",
    "        data=pd.read_csv(f\"Dataset/IHDP_a/ihdp_npci_train_{file_num}.csv\")\n",
    "    else:\n",
    "        data = pd.read_csv(f\"Dataset/IHDP_a/ihdp_npci_test_{file_num}.csv\")\n",
    "\n",
    "    x_data=pd.concat([data.iloc[:,0], data.iloc[:, 1:30]], axis = 1)\n",
    "    #x_data=data.iloc[:, 5:30]\n",
    "    y_data=data.iloc[:, 1]\n",
    "    return x_data,y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2319f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(x_data,y_data,batch_size):\n",
    "\n",
    "    x_train_sr=x_data[x_data['treatment']==0]\n",
    "    y_train_sr=y_data[x_data['treatment']==0]\n",
    "    x_train_tr=x_data[x_data['treatment']==1]\n",
    "    y_train_tr=y_data[x_data['treatment']==1]\n",
    "\n",
    "\n",
    "    train_data_sr = Data(np.array(x_train_sr), np.array(y_train_sr))\n",
    "    train_dataloader_sr = DataLoader(dataset=train_data_sr, batch_size=batch_size)\n",
    "\n",
    "    train_data_tr = Data(np.array(x_train_tr), np.array(y_train_tr))\n",
    "    train_dataloader_tr = DataLoader(dataset=train_data_tr, batch_size=batch_size)\n",
    "\n",
    "\n",
    "    return train_dataloader_sr, train_dataloader_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b92cc291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_loss(concat_true, concat_pred):\n",
    "    #computes a standard MSE loss for TARNet\n",
    "    y_true = concat_true[:, 0] #get individual vectors\n",
    "    t_true = concat_true[:, 1]\n",
    "\n",
    "    y0_pred = concat_pred[:, 0]\n",
    "    y1_pred = concat_pred[:, 1]\n",
    "\n",
    "    #Each head outputs a prediction for both potential outcomes\n",
    "    #We use t_true as a switch to only calculate the factual loss\n",
    "    loss0 = torch.sum((1. - t_true) * torch.square(y_true - y0_pred))\n",
    "    loss1 = torch.sum(t_true * torch.square(y_true - y1_pred))\n",
    "    #note Shi uses tf.reduce_sum for her losses instead of tf.reduce_mean.\n",
    "    #They should be equivalent but it's possible that having larger gradients accelerates convergence.\n",
    "    #You can always try changing it!\n",
    "    return loss0 + loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "536f4a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_pehe(data,y,model):\n",
    "    #data,y=get_data('test',i)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    data=data.to_numpy()\n",
    "    data=torch.from_numpy(data.astype(np.float32)).to(device)\n",
    "\n",
    "\n",
    "\n",
    "    concat_pred=model(data[:,5:30])\n",
    "    #dont forget to rescale the outcome before estimation!\n",
    "    #y0_pred = data['y_scaler'].inverse_transform(concat_pred[:, 0].reshape(-1, 1))\n",
    "    #y1_pred = data['y_scaler'].inverse_transform(concat_pred[:, 1].reshape(-1, 1))\n",
    "    cate_pred=concat_pred[:,1]-concat_pred[:,0]\n",
    "    cate_true=data[:,4]-data[:,3] #Hill's noiseless true values\n",
    "\n",
    "\n",
    "    cate_err=torch.mean( torch.square( ( (cate_true) - (cate_pred) ) ) )\n",
    "\n",
    "    return torch.sqrt(cate_err).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5226d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def loss_cal(X_data,y_data,net,device):\n",
    "    \n",
    "    x_train_sr=X_data[X_data['treatment']==0]\n",
    "    y_train_sr=y_data[X_data['treatment']==0]\n",
    "    x_train_tr=X_data[X_data['treatment']==1]\n",
    "    y_train_tr=y_data[X_data['treatment']==1]\n",
    "    xs_t=x_train_sr.iloc[:,0].to_numpy()\n",
    "    xt_t=x_train_tr.iloc[:,0].to_numpy()\n",
    "    \n",
    "    xs=x_train_sr.iloc[:,5:30].to_numpy()\n",
    "    xt=x_train_tr.iloc[:,5:30].to_numpy()\n",
    "    xs_t=torch.from_numpy(xs_t.astype(np.float32))\n",
    "    xt_t=torch.from_numpy(xt_t.astype(np.float32))\n",
    "    y_train_sr=y_train_sr.to_numpy()\n",
    "    y_train_tr=y_train_tr.to_numpy()\n",
    "    xs=torch.from_numpy(xs.astype(np.float32))\n",
    "    xt=torch.from_numpy(xt.astype(np.float32))\n",
    "    \n",
    "    y_train_sr=torch.from_numpy(y_train_sr.astype(np.float32))\n",
    "    y_train_tr=torch.from_numpy(y_train_tr.astype(np.float32))\n",
    "    \n",
    "    \n",
    "    input_data=torch.cat((xs,xt),0).to(device)\n",
    "    true_y=torch.unsqueeze(torch.cat((y_train_sr,y_train_tr),0), dim=1).to(device)\n",
    "    true_t=torch.unsqueeze(torch.cat((xs_t,xt_t),0), dim=1).to(device)\n",
    "    \n",
    "    \n",
    "    concat_true=torch.cat((true_y,true_t),1)\n",
    "    concat_pred=net(input_data)\n",
    "    loss=regression_loss(concat_true, concat_pred)\n",
    "    loss_2=y_MSE(concat_pred[0],concat_pred[1])\n",
    "    return loss.item()\n",
    "\n",
    "def cf_loss(xs,xt):\n",
    "\n",
    "        col =  [\"treatment\", \"y_factual\", \"y_cfactual\",]\n",
    "        for i in range(1,28):\n",
    "            col.append(\"x\"+str(i))\n",
    "\n",
    "        df_datac=pd.DataFrame(xs.numpy(),columns=col)\n",
    "        df_datat=pd.DataFrame(xt.numpy(),columns=col)\n",
    "        \n",
    "                \n",
    "        PhiC=xs[:,5:30]\n",
    "        PhiT=xt[:,5:30]\n",
    "              \n",
    "        \n",
    "        dists = torch.sqrt(torch.cdist(PhiC, PhiT))\n",
    "        c_index=torch.argmin(dists, dim=0).tolist()\n",
    "        t_index=torch.argmin(dists, dim=1).tolist()\n",
    "    \n",
    "        yT_nn=df_datac.iloc[c_index]['y_factual']\n",
    "        yC_nn=df_datat.iloc[t_index]['y_factual']\n",
    "        yT_nn=yT_nn.to_numpy()\n",
    "        yT_nn=torch.from_numpy(yT_nn.astype(np.float32))\n",
    "        yC_nn=yC_nn.to_numpy()\n",
    "        yC_nn=torch.from_numpy(yC_nn.astype(np.float32))\n",
    "        #y_nn = torch.cat([yT_nn, yC_nn],0) \n",
    "        return yC_nn,yT_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c05852e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_MSE=nn.MSELoss()\n",
    "#criterion_reg=regression_loss(concat_true,concat_pred)\n",
    "epochs=300\n",
    "#batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "89f5c61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bcb7c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[]\n",
    "val_loss=[]\n",
    "pehe_error=[]\n",
    "num_files=2\n",
    "def train_evaluate(param, model, trial,file_num):\n",
    "    #for nf in range(1,num_files):\n",
    "    x_data,y_data=get_data('train',file_num)\n",
    "    X_train, X_val,y_train, y_val = train_test_split(x_data,y_data ,\n",
    "                                       random_state=42, \n",
    "                                       test_size=0.20)\n",
    "    \n",
    "    #net=TarNet(25,.01)\n",
    "    #opt_net = torch.optim.Adam(net.parameters(), lr=1e-4)\n",
    "    \n",
    "   \n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    print(device)\n",
    "    optimizer = getattr(optim, param['optimizer'])(model.parameters(), lr= param['learning_rate'])\n",
    "    \n",
    "    #if use_cuda:\n",
    "\n",
    "        #model = model.cuda()\n",
    "    model = model.to(device)\n",
    "        #criterion = criterion.cuda()\n",
    "\n",
    "    for ep in range(1,epochs+1 ):\n",
    "\n",
    "        train_dataloader_sr, train_dataloader_tr=get_dataloader(X_train,y_train,param['batch_size'])\n",
    "\n",
    "        for batch_idx, (train_source_data, train_target_data) in enumerate(zip(train_dataloader_sr, train_dataloader_tr)):\n",
    "\n",
    "            xs,ys=train_source_data\n",
    "            xt,yt=train_target_data\n",
    "            yC_nn,yT_nn=cf_loss(xs,xt)\n",
    "            #print(xs)\n",
    "\n",
    "            xs_train=xs[:,5:30]\n",
    "            xt_train=xt[:,5:30]\n",
    "\n",
    "            train_x=torch.cat((xs_train,xt_train),0).to(device)\n",
    "            train_y=torch.unsqueeze(torch.cat((ys,yt),0), dim=1).to(device)\n",
    "            true_t=torch.unsqueeze(torch.cat((xs[:,0],xt[:,0]),0), dim=1).to(device)\n",
    "            concat_true=torch.cat((train_y,true_t),1).to(device)\n",
    "            concat_pred=model(train_x).to(device)\n",
    "\n",
    "            model.zero_grad()\n",
    "\n",
    "            #source_mse=criterion_reg(y0,ys)\n",
    "            #target_mse=criterion_reg(y1,yt)\n",
    "\n",
    "            #combined loss\n",
    "            combined_loss=regression_loss(concat_true,concat_pred)+(y_MSE(concat_pred[0:xs_train.shape[0],1],yC_nn.to(device)))+(y_MSE(concat_pred[xs_train.shape[0]:,0],yT_nn.to(device)))\n",
    "            #print('Training loss: ',combined_loss.item())\n",
    "            # backward propagation\n",
    "            combined_loss.backward()\n",
    "\n",
    "            # optimize\n",
    "            optimizer.step()\n",
    "        #train_loss.append(loss_cal(X_train,y_train,net))\n",
    "        #val_loss.append(loss_cal(X_val,y_val,net))\n",
    "        \n",
    "        # Add prune mechanism\n",
    "        #trial.report(accuracy, ep)\n",
    "\n",
    "        #if trial.should_prune():\n",
    "        #   raise optuna.exceptions.TrialPruned()\n",
    "            \n",
    "    #return cal_pehe(X_val,y_val,model),model\n",
    "    return loss_cal(X_val,y_val,model,device),model\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "19615b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:15:45,245]\u001b[0m A new study created in memory with name: no-name-f51b8bac-248c-4764-8e25-9b3f06640cfb\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:15:46,820]\u001b[0m Trial 0 finished with value: 225.5309600830078 and parameters: {'learning_rate': 5.6115164153345e-05, 'optimizer': 'Adam', 'batch_size': 157, 'RL11': 93, 'RL21': 93, 'RL32': 44, 'RG012': 446, 'RG022': 314, 'RG112': 367, 'RG122': 26}. Best is trial 0 with value: 225.5309600830078.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:15:48,971]\u001b[0m Trial 1 finished with value: 275.78924560546875 and parameters: {'learning_rate': 0.0008706020878304854, 'optimizer': 'Adam', 'batch_size': 53, 'RL11': 107, 'RL21': 167, 'RL32': 276, 'RG012': 230, 'RG022': 160, 'RG112': 320, 'RG122': 85}. Best is trial 0 with value: 225.5309600830078.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:15:50,398]\u001b[0m Trial 2 finished with value: 163.0251922607422 and parameters: {'learning_rate': 3.8396292998041685e-05, 'optimizer': 'SGD', 'batch_size': 203, 'RL11': 115, 'RL21': 271, 'RL32': 310, 'RG012': 39, 'RG022': 317, 'RG112': 100, 'RG122': 48}. Best is trial 2 with value: 163.0251922607422.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:15:52,704]\u001b[0m Trial 3 finished with value: 297.7108154296875 and parameters: {'learning_rate': 0.000790261954970823, 'optimizer': 'Adam', 'batch_size': 83, 'RL11': 64, 'RL21': 356, 'RL32': 234, 'RG012': 76, 'RG022': 262, 'RG112': 33, 'RG122': 467}. Best is trial 2 with value: 163.0251922607422.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:15:54,396]\u001b[0m Trial 4 finished with value: 192.56271362304688 and parameters: {'learning_rate': 3.292759134423613e-05, 'optimizer': 'Adam', 'batch_size': 137, 'RL11': 287, 'RL21': 107, 'RL32': 497, 'RG012': 401, 'RG022': 482, 'RG112': 460, 'RG122': 313}. Best is trial 2 with value: 163.0251922607422.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:15:58,969]\u001b[0m Trial 5 finished with value: 318.8458251953125 and parameters: {'learning_rate': 0.0006978281265126031, 'optimizer': 'SGD', 'batch_size': 19, 'RL11': 177, 'RL21': 209, 'RL32': 150, 'RG012': 427, 'RG022': 193, 'RG112': 155, 'RG122': 285}. Best is trial 2 with value: 163.0251922607422.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:00,830]\u001b[0m Trial 6 finished with value: 276.48590087890625 and parameters: {'learning_rate': 1.913588048769229e-05, 'optimizer': 'Adam', 'batch_size': 253, 'RL11': 399, 'RL21': 114, 'RL32': 18, 'RG012': 421, 'RG022': 367, 'RG112': 378, 'RG122': 399}. Best is trial 2 with value: 163.0251922607422.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:02,579]\u001b[0m Trial 7 finished with value: 391.9149475097656 and parameters: {'learning_rate': 1.4063366777718176e-05, 'optimizer': 'Adam', 'batch_size': 222, 'RL11': 325, 'RL21': 180, 'RL32': 47, 'RG012': 170, 'RG022': 177, 'RG112': 378, 'RG122': 332}. Best is trial 2 with value: 163.0251922607422.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:04,226]\u001b[0m Trial 8 finished with value: 235.14736938476562 and parameters: {'learning_rate': 0.000594874681321977, 'optimizer': 'Adam', 'batch_size': 185, 'RL11': 394, 'RL21': 294, 'RL32': 399, 'RG012': 261, 'RG022': 275, 'RG112': 228, 'RG122': 28}. Best is trial 2 with value: 163.0251922607422.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:06,169]\u001b[0m Trial 9 finished with value: 184.7571258544922 and parameters: {'learning_rate': 1.6435497475111308e-05, 'optimizer': 'SGD', 'batch_size': 86, 'RL11': 268, 'RL21': 467, 'RL32': 139, 'RG012': 219, 'RG022': 391, 'RG112': 129, 'RG122': 54}. Best is trial 2 with value: 163.0251922607422.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:07,825]\u001b[0m Trial 10 finished with value: 144.05978393554688 and parameters: {'learning_rate': 0.00010649438604541352, 'optimizer': 'SGD', 'batch_size': 207, 'RL11': 181, 'RL21': 409, 'RL32': 348, 'RG012': 23, 'RG022': 44, 'RG112': 34, 'RG122': 177}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:09,453]\u001b[0m Trial 11 finished with value: 159.49745178222656 and parameters: {'learning_rate': 0.00011605061325789702, 'optimizer': 'SGD', 'batch_size': 201, 'RL11': 176, 'RL21': 419, 'RL32': 344, 'RG012': 21, 'RG022': 19, 'RG112': 20, 'RG122': 178}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:11,180]\u001b[0m Trial 12 finished with value: 144.4960174560547 and parameters: {'learning_rate': 0.00014595432633183366, 'optimizer': 'SGD', 'batch_size': 255, 'RL11': 191, 'RL21': 504, 'RL32': 390, 'RG012': 115, 'RG022': 20, 'RG112': 37, 'RG122': 179}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:12,896]\u001b[0m Trial 13 finished with value: 148.20870971679688 and parameters: {'learning_rate': 0.00013450549446761032, 'optimizer': 'SGD', 'batch_size': 246, 'RL11': 191, 'RL21': 511, 'RL32': 439, 'RG012': 127, 'RG022': 19, 'RG112': 204, 'RG122': 177}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:14,512]\u001b[0m Trial 14 finished with value: 166.9627685546875 and parameters: {'learning_rate': 0.0002096949254617045, 'optimizer': 'SGD', 'batch_size': 177, 'RL11': 214, 'RL21': 392, 'RL32': 392, 'RG012': 334, 'RG022': 97, 'RG112': 79, 'RG122': 190}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-05-16 17:16:16,183]\u001b[0m Trial 15 failed with parameters: {'learning_rate': 0.0002289712776988392, 'optimizer': 'SGD', 'batch_size': 232, 'RL11': 501, 'RL21': 18, 'RL32': 223, 'RG012': 119, 'RG022': 92, 'RG112': 179, 'RG122': 129} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-16 17:16:16,184]\u001b[0m Trial 15 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-05-16 17:16:17,850]\u001b[0m Trial 16 failed with parameters: {'learning_rate': 0.00026914767644166604, 'optimizer': 'SGD', 'batch_size': 230, 'RL11': 25, 'RL21': 504, 'RL32': 485, 'RG012': 113, 'RG022': 86, 'RG112': 178, 'RG122': 126} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-16 17:16:17,851]\u001b[0m Trial 16 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-05-16 17:16:19,505]\u001b[0m Trial 17 failed with parameters: {'learning_rate': 0.0002195820843111018, 'optimizer': 'SGD', 'batch_size': 226, 'RL11': 495, 'RL21': 505, 'RL32': 482, 'RG012': 107, 'RG022': 89, 'RG112': 186, 'RG122': 129} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-16 17:16:19,505]\u001b[0m Trial 17 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-05-16 17:16:21,380]\u001b[0m Trial 18 failed with parameters: {'learning_rate': 0.0002665481042547526, 'optimizer': 'SGD', 'batch_size': 231, 'RL11': 37, 'RL21': 509, 'RL32': 499, 'RG012': 116, 'RG022': 90, 'RG112': 151, 'RG122': 230} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-16 17:16:21,381]\u001b[0m Trial 18 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-05-16 17:16:23,133]\u001b[0m Trial 19 failed with parameters: {'learning_rate': 0.0002478278634130184, 'optimizer': 'SGD', 'batch_size': 230, 'RL11': 20, 'RL21': 512, 'RL32': 492, 'RG012': 114, 'RG022': 90, 'RG112': 186, 'RG122': 134} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-16 17:16:23,134]\u001b[0m Trial 19 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-05-16 17:16:24,810]\u001b[0m Trial 20 failed with parameters: {'learning_rate': 0.00023400383905811692, 'optimizer': 'SGD', 'batch_size': 225, 'RL11': 499, 'RL21': 508, 'RL32': 495, 'RG012': 105, 'RG022': 87, 'RG112': 170, 'RG122': 132} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-16 17:16:24,811]\u001b[0m Trial 20 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:26,455]\u001b[0m Trial 21 finished with value: 146.71310424804688 and parameters: {'learning_rate': 7.367344712091265e-05, 'optimizer': 'SGD', 'batch_size': 231, 'RL11': 488, 'RL21': 501, 'RL32': 511, 'RG012': 98, 'RG022': 82, 'RG112': 153, 'RG122': 231}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:28,172]\u001b[0m Trial 22 finished with value: 163.43223571777344 and parameters: {'learning_rate': 0.0002789359962595687, 'optimizer': 'SGD', 'batch_size': 256, 'RL11': 21, 'RL21': 23, 'RL32': 219, 'RG012': 160, 'RG022': 94, 'RG112': 59, 'RG122': 100}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:29,781]\u001b[0m Trial 23 finished with value: 162.7947998046875 and parameters: {'learning_rate': 0.00019533062940650593, 'optimizer': 'SGD', 'batch_size': 217, 'RL11': 233, 'RL21': 340, 'RL32': 367, 'RG012': 73, 'RG022': 66, 'RG112': 272, 'RG122': 137}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:31,337]\u001b[0m Trial 24 finished with value: 197.3776092529297 and parameters: {'learning_rate': 8.174722873444712e-05, 'optimizer': 'SGD', 'batch_size': 120, 'RL11': 150, 'RL21': 439, 'RL32': 457, 'RG012': 342, 'RG022': 120, 'RG112': 484, 'RG122': 222}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-05-16 17:16:33,019]\u001b[0m Trial 25 failed with parameters: {'learning_rate': 0.000358494130231387, 'optimizer': 'SGD', 'batch_size': 175, 'RL11': 345, 'RL21': 374, 'RL32': 317, 'RG012': 148, 'RG022': 233, 'RG112': 178, 'RG122': 128} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-16 17:16:33,020]\u001b[0m Trial 25 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-05-16 17:16:34,666]\u001b[0m Trial 26 failed with parameters: {'learning_rate': 0.0002938556570512552, 'optimizer': 'SGD', 'batch_size': 165, 'RL11': 325, 'RL21': 371, 'RL32': 313, 'RG012': 169, 'RG022': 219, 'RG112': 186, 'RG122': 131} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-16 17:16:34,667]\u001b[0m Trial 26 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:36,297]\u001b[0m Trial 27 finished with value: 187.84918212890625 and parameters: {'learning_rate': 0.00035705097909553244, 'optimizer': 'SGD', 'batch_size': 157, 'RL11': 334, 'RL21': 370, 'RL32': 310, 'RG012': 17, 'RG022': 18, 'RG112': 175, 'RG122': 131}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:38,068]\u001b[0m Trial 28 finished with value: 158.3787841796875 and parameters: {'learning_rate': 0.00012706810749944428, 'optimizer': 'SGD', 'batch_size': 186, 'RL11': 247, 'RL21': 457, 'RL32': 423, 'RG012': 148, 'RG022': 148, 'RG112': 99, 'RG122': 371}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:39,971]\u001b[0m Trial 29 finished with value: 161.284423828125 and parameters: {'learning_rate': 7.428493869850675e-05, 'optimizer': 'SGD', 'batch_size': 224, 'RL11': 496, 'RL21': 512, 'RL32': 512, 'RG012': 99, 'RG022': 68, 'RG112': 131, 'RG122': 244}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:41,783]\u001b[0m Trial 30 finished with value: 150.43861389160156 and parameters: {'learning_rate': 6.02133479009758e-05, 'optimizer': 'SGD', 'batch_size': 233, 'RL11': 510, 'RL21': 478, 'RL32': 470, 'RG012': 105, 'RG022': 71, 'RG112': 16, 'RG122': 228}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:43,749]\u001b[0m Trial 31 finished with value: 164.53355407714844 and parameters: {'learning_rate': 9.696821856699431e-05, 'optimizer': 'SGD', 'batch_size': 232, 'RL11': 446, 'RL21': 419, 'RL32': 347, 'RG012': 498, 'RG022': 233, 'RG112': 69, 'RG122': 269}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:45,571]\u001b[0m Trial 32 finished with value: 185.86605834960938 and parameters: {'learning_rate': 0.00015954867018455252, 'optimizer': 'SGD', 'batch_size': 206, 'RL11': 307, 'RL21': 319, 'RL32': 417, 'RG012': 64, 'RG022': 123, 'RG112': 194, 'RG122': 133}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:47,332]\u001b[0m Trial 33 finished with value: 162.53656005859375 and parameters: {'learning_rate': 9.817199773010843e-05, 'optimizer': 'SGD', 'batch_size': 238, 'RL11': 152, 'RL21': 488, 'RL32': 476, 'RG012': 120, 'RG022': 54, 'RG112': 140, 'RG122': 209}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:49,088]\u001b[0m Trial 34 finished with value: 190.06002807617188 and parameters: {'learning_rate': 0.00016718377454763586, 'optimizer': 'SGD', 'batch_size': 167, 'RL11': 356, 'RL21': 404, 'RL32': 321, 'RG012': 194, 'RG022': 44, 'RG112': 257, 'RG122': 156}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:50,761]\u001b[0m Trial 35 finished with value: 171.64720153808594 and parameters: {'learning_rate': 4.887255759216168e-05, 'optimizer': 'SGD', 'batch_size': 123, 'RL11': 215, 'RL21': 439, 'RL32': 380, 'RG012': 58, 'RG022': 215, 'RG112': 62, 'RG122': 286}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:52,605]\u001b[0m Trial 36 finished with value: 154.33045959472656 and parameters: {'learning_rate': 8.948063412375047e-05, 'optimizer': 'SGD', 'batch_size': 202, 'RL11': 144, 'RL21': 381, 'RL32': 277, 'RG012': 308, 'RG022': 131, 'RG112': 111, 'RG122': 104}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:54,294]\u001b[0m Trial 37 finished with value: 162.5286865234375 and parameters: {'learning_rate': 5.7223484846347835e-05, 'optimizer': 'SGD', 'batch_size': 143, 'RL11': 71, 'RL21': 512, 'RL32': 185, 'RG012': 193, 'RG022': 96, 'RG112': 47, 'RG122': 250}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:56,123]\u001b[0m Trial 38 finished with value: 147.54518127441406 and parameters: {'learning_rate': 7.187519318371559e-05, 'optimizer': 'SGD', 'batch_size': 243, 'RL11': 466, 'RL21': 458, 'RL32': 441, 'RG012': 84, 'RG022': 498, 'RG112': 167, 'RG122': 334}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:57,997]\u001b[0m Trial 39 finished with value: 155.69903564453125 and parameters: {'learning_rate': 6.477942869311063e-05, 'optimizer': 'SGD', 'batch_size': 255, 'RL11': 462, 'RL21': 462, 'RL32': 447, 'RG012': 102, 'RG022': 446, 'RG112': 164, 'RG122': 360}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:16:59,818]\u001b[0m Trial 40 finished with value: 148.98403930664062 and parameters: {'learning_rate': 0.00011260693187092923, 'optimizer': 'SGD', 'batch_size': 213, 'RL11': 451, 'RL21': 435, 'RL32': 487, 'RG012': 46, 'RG022': 500, 'RG112': 275, 'RG122': 314}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:17:01,759]\u001b[0m Trial 41 finished with value: 154.44464111328125 and parameters: {'learning_rate': 4.506181054974253e-05, 'optimizer': 'SGD', 'batch_size': 236, 'RL11': 401, 'RL21': 482, 'RL32': 405, 'RG012': 80, 'RG022': 388, 'RG112': 332, 'RG122': 446}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:17:03,862]\u001b[0m Trial 42 finished with value: 148.75193786621094 and parameters: {'learning_rate': 7.540632963321562e-05, 'optimizer': 'Adam', 'batch_size': 194, 'RL11': 484, 'RL21': 489, 'RL32': 433, 'RG012': 131, 'RG022': 443, 'RG112': 90, 'RG122': 195}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:17:05,761]\u001b[0m Trial 43 finished with value: 156.35504150390625 and parameters: {'learning_rate': 3.694124264658774e-05, 'optimizer': 'SGD', 'batch_size': 224, 'RL11': 119, 'RL21': 327, 'RL32': 351, 'RG012': 27, 'RG022': 330, 'RG112': 232, 'RG122': 437}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:17:07,612]\u001b[0m Trial 44 finished with value: 171.35833740234375 and parameters: {'learning_rate': 0.0001447184593495064, 'optimizer': 'SGD', 'batch_size': 243, 'RL11': 423, 'RL21': 240, 'RL32': 512, 'RG012': 88, 'RG022': 273, 'RG112': 116, 'RG122': 276}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:17:10,660]\u001b[0m Trial 45 finished with value: 198.59507751464844 and parameters: {'learning_rate': 3.0885909091845585e-05, 'optimizer': 'Adam', 'batch_size': 100, 'RL11': 278, 'RL21': 446, 'RL32': 286, 'RG012': 46, 'RG022': 42, 'RG112': 38, 'RG122': 155}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:17:15,865]\u001b[0m Trial 46 finished with value: 176.3148956298828 and parameters: {'learning_rate': 6.986662264417684e-05, 'optimizer': 'SGD', 'batch_size': 25, 'RL11': 372, 'RL21': 411, 'RL32': 462, 'RG012': 249, 'RG022': 171, 'RG112': 313, 'RG122': 315}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:17:18,584]\u001b[0m Trial 47 finished with value: 169.7120819091797 and parameters: {'learning_rate': 9.563299777591729e-05, 'optimizer': 'Adam', 'batch_size': 57, 'RL11': 430, 'RL21': 360, 'RL32': 247, 'RG012': 182, 'RG022': 334, 'RG112': 201, 'RG122': 351}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:17:20,353]\u001b[0m Trial 48 finished with value: 172.84349060058594 and parameters: {'learning_rate': 2.5963512662012436e-05, 'optimizer': 'SGD', 'batch_size': 215, 'RL11': 96, 'RL21': 288, 'RL32': 370, 'RG012': 139, 'RG022': 88, 'RG112': 429, 'RG122': 407}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n",
      "/tmp/ipykernel_35776/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 17:17:22,344]\u001b[0m Trial 49 finished with value: 151.86009216308594 and parameters: {'learning_rate': 0.00011632326671874174, 'optimizer': 'SGD', 'batch_size': 244, 'RL11': 196, 'RL21': 507, 'RL32': 430, 'RG012': 220, 'RG022': 20, 'RG112': 204, 'RG122': 501}. Best is trial 10 with value: 144.05978393554688.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'use_cuda' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[146], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m best_val,model\u001b[38;5;241m=\u001b[39mtrain_evaluate(study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams, best_model, study\u001b[38;5;241m.\u001b[39mbest_trial,i)\n\u001b[1;32m      9\u001b[0m data,y\u001b[38;5;241m=\u001b[39mget_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m,i)\n\u001b[0;32m---> 10\u001b[0m pehe\u001b[38;5;241m=\u001b[39m\u001b[43mcal_pehe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m pehe_total\u001b[38;5;241m.\u001b[39mappend(pehe)\n",
      "Cell \u001b[0;32mIn[141], line 3\u001b[0m, in \u001b[0;36mcal_pehe\u001b[0;34m(data, y, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcal_pehe\u001b[39m(data,y,model):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m#data,y=get_data('test',i)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43muse_cuda\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m      6\u001b[0m     data\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfrom_numpy(data\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'use_cuda' is not defined"
     ]
    }
   ],
   "source": [
    "pehe_total=[]\n",
    "for i in range(5,7):\n",
    "    func = lambda trial: objective(trial, i)\n",
    "    study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    study.optimize(func, n_trials=50)\n",
    "    best_trial = study.best_trial\n",
    "    best_model=TarNet(study.best_trial.params)\n",
    "    best_val,model=train_evaluate(study.best_trial.params, best_model, study.best_trial,i)\n",
    "    data,y=get_data('test',i)\n",
    "    pehe=cal_pehe(data,y,model)\n",
    "\n",
    "    pehe_total.append(pehe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a97b7951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7888284027576447\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(pehe_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cf13a475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7274773120880127, 0.8501794934272766]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e536b889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(pehe_total[0:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6757e606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7245088219642639,\n",
       " 1.0319709777832031,\n",
       " 0.8922997713088989,\n",
       " 0.766045093536377,\n",
       " 1.176272988319397,\n",
       " 1.3779881000518799,\n",
       " 0.33619603514671326,\n",
       " 0.9627038240432739,\n",
       " 0.8635401725769043,\n",
       " 1.3651361465454102,\n",
       " 0.9023053050041199,\n",
       " 0.7707643508911133,\n",
       " 0.6479784250259399,\n",
       " 1.3890775442123413,\n",
       " 1.2930279970169067,\n",
       " 0.8717934489250183,\n",
       " 0.5604594945907593,\n",
       " 0.4141177237033844,\n",
       " 0.9313862323760986,\n",
       " 1.3393807411193848,\n",
       " 0.9354116320610046,\n",
       " 0.5097612142562866,\n",
       " 0.8281165957450867,\n",
       " 0.6784378290176392,\n",
       " 0.9889419674873352,\n",
       " 0.8551837205886841,\n",
       " 0.976718544960022,\n",
       " 0.8554731607437134,\n",
       " 1.5037286281585693,\n",
       " 0.6007119417190552,\n",
       " 0.5339930653572083,\n",
       " 0.6747851967811584,\n",
       " 0.815698504447937,\n",
       " 0.8607384562492371,\n",
       " 0.7166107892990112,\n",
       " 0.6790837049484253,\n",
       " 0.567247748374939,\n",
       " 0.45495477318763733,\n",
       " 1.0859042406082153,\n",
       " 1.9381632804870605,\n",
       " 1.7002204656600952,\n",
       " 0.7606197595596313,\n",
       " 0.34149885177612305,\n",
       " 0.8747959733009338,\n",
       " 0.5832961797714233,\n",
       " 0.5637949705123901,\n",
       " 0.8216122984886169,\n",
       " 1.4024803638458252,\n",
       " 2.833282232284546,\n",
       " 2.11715030670166,\n",
       " 0.9226074814796448,\n",
       " 0.387696236371994,\n",
       " 0.5169910192489624,\n",
       " 2.130324363708496,\n",
       " 0.6147360801696777,\n",
       " 1.5111188888549805,\n",
       " 0.7361528277397156,\n",
       " 1.9234901666641235,\n",
       " 0.44361335039138794,\n",
       " 0.48345568776130676,\n",
       " 0.9034720063209534,\n",
       " 0.3778102695941925,\n",
       " 0.587611973285675,\n",
       " 0.2885318100452423,\n",
       " 0.5243985056877136,\n",
       " 0.9272621870040894,\n",
       " 1.5542900562286377,\n",
       " 0.48880594968795776,\n",
       " 1.0982612371444702,\n",
       " 1.053787112236023,\n",
       " 1.5719798803329468,\n",
       " 1.0619170665740967,\n",
       " 1.243140697479248,\n",
       " 0.7549936771392822,\n",
       " 1.397834300994873,\n",
       " nan,\n",
       " 0.9777540564537048,\n",
       " 1.1433939933776855,\n",
       " 1.078965425491333,\n",
       " 1.3572587966918945,\n",
       " 0.8846351504325867,\n",
       " 2.7632808685302734,\n",
       " 0.7164131999015808,\n",
       " 1.1646203994750977,\n",
       " 0.38471511006355286,\n",
       " 0.9528924822807312,\n",
       " 0.7543814778327942,\n",
       " 19.884397506713867,\n",
       " 0.7215575575828552,\n",
       " 0.5272590517997742,\n",
       " 0.9076446294784546,\n",
       " 0.5668836236000061,\n",
       " 0.35193508863449097,\n",
       " 0.4393121004104614,\n",
       " 0.7004181742668152,\n",
       " 1.843449354171753,\n",
       " 0.7884598970413208,\n",
       " 0.7063225507736206,\n",
       " 0.9662765264511108,\n",
       " 1.3312768936157227]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pehe_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6b002da",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"CFR_y_loss_1_100_(IHDPa-Hyper_val_300ep_outsample).csv\", pehe_total,delimiter =\", \", fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb8e4efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for key, value in best_trial.params.items():\n",
    "#    print(\"{}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f0b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ate_pred=torch.mean(cate_pred)\n",
    "#print(\"Estimated ATE (True is 4):\", ate_pred.detach().numpy(),'\\n\\n')\n",
    "\n",
    "#print(\"Individualized CATE Estimates: BLUE\")\n",
    "#print(pd.Series(cate_pred.detach().numpy()).plot.kde(color='blue'))\n",
    "#print(\"Individualized CATE True: Green\")\n",
    "#print(pd.Series(cate_true.detach().numpy()).plot.kde(color='green'))\n",
    "\n",
    "#print(\"\\nError CATE Estimates: RED\")\n",
    "#print(pd.Series(cate_pred.detach().numpy()-cate_true.detach().numpy()).plot.kde(color='red'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
