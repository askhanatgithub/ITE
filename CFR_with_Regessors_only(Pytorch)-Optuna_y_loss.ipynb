{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52542919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fae09fb52f0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "#from geomloss import SamplesLoss\n",
    "from torch.autograd import Function\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.functional import normalize\n",
    "#from torchmetrics.classification import BinaryAccuracy\n",
    "#from torchmetrics.classification import BinaryF1Score\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e50bd733",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TarNet(nn.Module):\n",
    "    def __init__(self,params):\n",
    "        super(TarNet, self).__init__()\n",
    "        self.encoder1 = nn.Linear(25, params['RL11'])\n",
    "        self.encoder2 = nn.Linear(params['RL11'], params['RL21'])\n",
    "        self.encoder3 = nn.Linear(params['RL21'], params['RL32'])\n",
    "\n",
    "        self.regressor1_y0 = nn.Sequential(\n",
    "            nn.Linear(params['RL32'], params['RG012']),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=.01),\n",
    "        )\n",
    "        self.regressor2_y0 = nn.Sequential(\n",
    "            nn.Linear(params['RG012'], params['RG022']),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=.01),\n",
    "        )\n",
    "        self.regressorO_y0 = nn.Linear(params['RG022'], 1)\n",
    "\n",
    "        self.regressor1_y1 = nn.Sequential(\n",
    "            nn.Linear(params['RL32'], params['RG112']),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=.01),\n",
    "        )\n",
    "        self.regressor2_y1 = nn.Sequential(\n",
    "            nn.Linear(params['RG112'], params['RG122']),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(p=.01),\n",
    "        )\n",
    "        self.regressorO_y1 = nn.Linear(params['RG122'], 1)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = nn.functional.elu(self.encoder1(inputs))\n",
    "        x = nn.functional.elu(self.encoder2(x))\n",
    "        phi = nn.functional.elu(self.encoder3(x))\n",
    "\n",
    "        out_y0 = self.regressor1_y0(phi)\n",
    "        out_y0 = self.regressor2_y0(out_y0)\n",
    "        y0 = self.regressorO_y0(out_y0)\n",
    "\n",
    "        out_y1 = self.regressor1_y1(phi)\n",
    "        out_y1 = self.regressor2_y1(out_y1)\n",
    "        y1 = self.regressorO_y1(out_y1)\n",
    "\n",
    "        concat = torch.cat((y0, y1), 1)\n",
    "        return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70c58121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial,i):\n",
    "\n",
    "    params = {\n",
    "          'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
    "          'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\"]),\n",
    "          'batch_size':trial.suggest_int('batch_size', 8, 256),\n",
    "          'RL11':trial.suggest_int('RL11', 16, 512),\n",
    "          'RL21': trial.suggest_int('RL21', 16, 512),\n",
    "          'RL32': trial.suggest_int('RL32', 16, 512),\n",
    "          'RG012':trial.suggest_int('RG012', 16, 512),\n",
    "        'RG022':trial.suggest_int('RG022', 16, 512),\n",
    "        'RG112':trial.suggest_int('RG112', 16, 512),\n",
    "        'RG122':trial.suggest_int('RG122', 16, 512),\n",
    "          \n",
    "          }\n",
    "\n",
    "    model = TarNet(params)\n",
    "\n",
    "    pehe,model= train_evaluate(params, model, trial,i)\n",
    "\n",
    "    return pehe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48800d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y.astype(np.float32))\n",
    "        self.len = self.X.shape[0]\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "   \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d80cf340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_type,file_num):\n",
    "\n",
    "    if(data_type=='train'):\n",
    "        data=pd.read_csv(f\"Dataset/IHDP_a/ihdp_npci_train_{file_num}.csv\")\n",
    "    else:\n",
    "        data = pd.read_csv(f\"Dataset/IHDP_a/ihdp_npci_test_{file_num}.csv\")\n",
    "\n",
    "    x_data=pd.concat([data.iloc[:,0], data.iloc[:, 1:30]], axis = 1)\n",
    "    #x_data=data.iloc[:, 5:30]\n",
    "    y_data=data.iloc[:, 1]\n",
    "    return x_data,y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2319f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(x_data,y_data,batch_size):\n",
    "\n",
    "    x_train_sr=x_data[x_data['treatment']==0]\n",
    "    y_train_sr=y_data[x_data['treatment']==0]\n",
    "    x_train_tr=x_data[x_data['treatment']==1]\n",
    "    y_train_tr=y_data[x_data['treatment']==1]\n",
    "\n",
    "\n",
    "    train_data_sr = Data(np.array(x_train_sr), np.array(y_train_sr))\n",
    "    train_dataloader_sr = DataLoader(dataset=train_data_sr, batch_size=batch_size)\n",
    "\n",
    "    train_data_tr = Data(np.array(x_train_tr), np.array(y_train_tr))\n",
    "    train_dataloader_tr = DataLoader(dataset=train_data_tr, batch_size=batch_size)\n",
    "\n",
    "\n",
    "    return train_dataloader_sr, train_dataloader_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b92cc291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_loss(concat_true, concat_pred):\n",
    "    #computes a standard MSE loss for TARNet\n",
    "    y_true = concat_true[:, 0] #get individual vectors\n",
    "    t_true = concat_true[:, 1]\n",
    "\n",
    "    y0_pred = concat_pred[:, 0]\n",
    "    y1_pred = concat_pred[:, 1]\n",
    "\n",
    "    #Each head outputs a prediction for both potential outcomes\n",
    "    #We use t_true as a switch to only calculate the factual loss\n",
    "    loss0 = torch.sum((1. - t_true) * torch.square(y_true - y0_pred))\n",
    "    loss1 = torch.sum(t_true * torch.square(y_true - y1_pred))\n",
    "    #note Shi uses tf.reduce_sum for her losses instead of tf.reduce_mean.\n",
    "    #They should be equivalent but it's possible that having larger gradients accelerates convergence.\n",
    "    #You can always try changing it!\n",
    "    return loss0 + loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "536f4a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_pehe(data,y,model):\n",
    "    #data,y=get_data('test',i)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    data=data.to_numpy()\n",
    "    data=torch.from_numpy(data.astype(np.float32)).to(device)\n",
    "\n",
    "\n",
    "\n",
    "    concat_pred=model(data[:,5:30])\n",
    "    #dont forget to rescale the outcome before estimation!\n",
    "    #y0_pred = data['y_scaler'].inverse_transform(concat_pred[:, 0].reshape(-1, 1))\n",
    "    #y1_pred = data['y_scaler'].inverse_transform(concat_pred[:, 1].reshape(-1, 1))\n",
    "    cate_pred=concat_pred[:,1]-concat_pred[:,0]\n",
    "    cate_true=data[:,4]-data[:,3] #Hill's noiseless true values\n",
    "\n",
    "\n",
    "    cate_err=torch.mean( torch.square( ( (cate_true) - (cate_pred) ) ) )\n",
    "\n",
    "    return torch.sqrt(cate_err).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5226d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def loss_cal(X_data,y_data,net,device):\n",
    "    \n",
    "    x_train_sr=X_data[X_data['treatment']==0]\n",
    "    y_train_sr=y_data[X_data['treatment']==0]\n",
    "    x_train_tr=X_data[X_data['treatment']==1]\n",
    "    y_train_tr=y_data[X_data['treatment']==1]\n",
    "    xs_t=x_train_sr.iloc[:,0].to_numpy()\n",
    "    xt_t=x_train_tr.iloc[:,0].to_numpy()\n",
    "    \n",
    "    xs=x_train_sr.iloc[:,5:30].to_numpy()\n",
    "    xt=x_train_tr.iloc[:,5:30].to_numpy()\n",
    "    xs_t=torch.from_numpy(xs_t.astype(np.float32))\n",
    "    xt_t=torch.from_numpy(xt_t.astype(np.float32))\n",
    "    y_train_sr=y_train_sr.to_numpy()\n",
    "    y_train_tr=y_train_tr.to_numpy()\n",
    "    xs=torch.from_numpy(xs.astype(np.float32))\n",
    "    xt=torch.from_numpy(xt.astype(np.float32))\n",
    "    \n",
    "    y_train_sr=torch.from_numpy(y_train_sr.astype(np.float32))\n",
    "    y_train_tr=torch.from_numpy(y_train_tr.astype(np.float32))\n",
    "    \n",
    "    \n",
    "    input_data=torch.cat((xs,xt),0).to(device)\n",
    "    true_y=torch.unsqueeze(torch.cat((y_train_sr,y_train_tr),0), dim=1).to(device)\n",
    "    true_t=torch.unsqueeze(torch.cat((xs_t,xt_t),0), dim=1).to(device)\n",
    "    \n",
    "    \n",
    "    concat_true=torch.cat((true_y,true_t),1)\n",
    "    concat_pred=net(input_data)\n",
    "    loss=regression_loss(concat_true, concat_pred)\n",
    "    loss_2=y_MSE(concat_pred[0],concat_pred[1])\n",
    "    return loss.item()\n",
    "\n",
    "def cf_loss(xs,xt):\n",
    "\n",
    "        #col =  [\"treatment\", \"y_factual\", \"y_cfactual\",]\n",
    "        #for i in range(1,28):\n",
    "        #    col.append(\"x\"+str(i))\n",
    "\n",
    "        #df_datac=pd.DataFrame(xs.numpy(),columns=col)\n",
    "        #df_datat=pd.DataFrame(xt.numpy(),columns=col)\n",
    "        \n",
    "                \n",
    "        PhiC=xs[:,5:30]\n",
    "        PhiT=xt[:,5:30]\n",
    "              \n",
    "        \n",
    "        dists = torch.sqrt(torch.cdist(PhiC, PhiT))\n",
    "        #c_index=torch.argmin(dists, dim=0).tolist()\n",
    "        #t_index=torch.argmin(dists, dim=1).tolist()\n",
    "        #yT_nn=df_datac.iloc[c_index]['y_factual']\n",
    "        #yC_nn=df_datat.iloc[t_index]['y_factual']\n",
    "        \n",
    "        \n",
    "        c_index=torch.argmin(dists, dim=0)\n",
    "        t_index=torch.argmin(dists, dim=1)\n",
    "        yT_nn=xs[c_index,1]\n",
    "        yC_nn=xt[t_index,1]\n",
    "        \n",
    "        \n",
    "        #yT_nn=yT_nn.to_numpy()\n",
    "        #yT_nn=torch.from_numpy(yT_nn.astype(np.float32))\n",
    "        #yC_nn=yC_nn.to_numpy()\n",
    "        #yC_nn=torch.from_numpy(yC_nn.astype(np.float32))\n",
    "       \n",
    "        return yC_nn,yT_nn\n",
    "    \n",
    "def cf_loss_prop(xs,xt):\n",
    "\n",
    "        #col =  [\"treatment\", \"y_factual\", \"y_cfactual\",]\n",
    "        #for i in range(1,28):\n",
    "        #    col.append(\"x\"+str(i))\n",
    "\n",
    "        #df_datac=pd.DataFrame(xs.numpy(),columns=col)\n",
    "        #df_datat=pd.DataFrame(xt.numpy(),columns=col)\n",
    "        \n",
    "                \n",
    "        PhiC=xs[:,5:30]\n",
    "        PhiT=xt[:,5:30]\n",
    "              \n",
    "        \n",
    "        dists = torch.sqrt(torch.cdist(PhiC, PhiT))\n",
    "        #c_index=torch.argmin(dists, dim=0).tolist()\n",
    "        #t_index=torch.argmin(dists, dim=1).tolist()\n",
    "        #yT_nn=df_datac.iloc[c_index]['y_factual']\n",
    "        #yC_nn=df_datat.iloc[t_index]['y_factual']\n",
    "        \n",
    "        \n",
    "        c_index=torch.argmin(dists, dim=0)\n",
    "        t_index=torch.argmin(dists, dim=1)\n",
    "        yT_nn=xs[c_index,1]\n",
    "        yC_nn=xt[t_index,1]\n",
    "        \n",
    "        \n",
    "        #yT_nn=yT_nn.to_numpy()\n",
    "        #yT_nn=torch.from_numpy(yT_nn.astype(np.float32))\n",
    "        #yC_nn=yC_nn.to_numpy()\n",
    "        #yC_nn=torch.from_numpy(yC_nn.astype(np.float32))\n",
    "       \n",
    "        return yC_nn,yT_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c05852e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_MSE=nn.MSELoss()\n",
    "#criterion_reg=regression_loss(concat_true,concat_pred)\n",
    "epochs=300\n",
    "#batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b6df80b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bcb7c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=[]\n",
    "val_loss=[]\n",
    "pehe_error=[]\n",
    "num_files=2\n",
    "def train_evaluate(param, model, trial,file_num):\n",
    "    #for nf in range(1,num_files):\n",
    "    x_data,y_data=get_data('train',file_num)\n",
    "    X_train, X_val,y_train, y_val = train_test_split(x_data,y_data ,\n",
    "                                       random_state=42, \n",
    "                                       test_size=0.20)\n",
    "    \n",
    "    #net=TarNet(25,.01)\n",
    "    #opt_net = torch.optim.Adam(net.parameters(), lr=1e-4)\n",
    "    \n",
    "   \n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    optimizer = getattr(optim, param['optimizer'])(model.parameters(), lr= param['learning_rate'])\n",
    "    \n",
    "    #if use_cuda:\n",
    "\n",
    "        #model = model.cuda()\n",
    "    model = model.to(device)\n",
    "        #criterion = criterion.cuda()\n",
    "\n",
    "    for ep in range(1,epochs+1 ):\n",
    "\n",
    "        train_dataloader_sr, train_dataloader_tr=get_dataloader(X_train,y_train,param['batch_size'])\n",
    "\n",
    "        for batch_idx, (train_source_data, train_target_data) in enumerate(zip(train_dataloader_sr, train_dataloader_tr)):\n",
    "\n",
    "            xs,ys=train_source_data\n",
    "            xt,yt=train_target_data\n",
    "            yC_nn,yT_nn=cf_loss(xs,xt)\n",
    "            #print(xs)\n",
    "\n",
    "            xs_train=xs[:,5:30]\n",
    "            xt_train=xt[:,5:30]\n",
    "\n",
    "            train_x=torch.cat((xs_train,xt_train),0).to(device)\n",
    "            train_y=torch.unsqueeze(torch.cat((ys,yt),0), dim=1).to(device)\n",
    "            true_t=torch.unsqueeze(torch.cat((xs[:,0],xt[:,0]),0), dim=1).to(device)\n",
    "            concat_true=torch.cat((train_y,true_t),1).to(device)\n",
    "            concat_pred=model(train_x).to(device)\n",
    "\n",
    "            model.zero_grad()\n",
    "\n",
    "            #source_mse=criterion_reg(y0,ys)\n",
    "            #target_mse=criterion_reg(y1,yt)\n",
    "            #cf_los=(y_MSE(concat_pred[0:xs_train.shape[0],1],yC_nn.to(device)))+(y_MSE(concat_pred[xs_train.shape[0]:,0],yT_nn.to(device)))\n",
    "            cf_los_1=torch.sum(torch.abs(concat_pred[0:xs_train.shape[0],1]-yC_nn.to(device)))\n",
    "            cf_los_2=torch.sum(torch.abs(concat_pred[xs_train.shape[0]:,0]-yT_nn.to(device)))\n",
    "            cf_los=cf_los_1+cf_los_2\n",
    "            #combined loss\n",
    "            combined_loss=regression_loss(concat_true,concat_pred)+cf_los #add tradeoff term here with between two\n",
    "            #losses\n",
    "                        #print('Training loss: ',combined_loss.item())\n",
    "            # backward propagation\n",
    "            combined_loss.backward()\n",
    "\n",
    "            # optimize\n",
    "            optimizer.step()\n",
    "        #train_loss.append(loss_cal(X_train,y_train,net))\n",
    "        #val_loss.append(loss_cal(X_val,y_val,net))\n",
    "        \n",
    "        # Add prune mechanism\n",
    "        #trial.report(accuracy, ep)\n",
    "\n",
    "        #if trial.should_prune():\n",
    "        #   raise optuna.exceptions.TrialPruned()\n",
    "            \n",
    "    #return cal_pehe(X_val,y_val,model),model\n",
    "    return loss_cal(X_val,y_val,model,device),model\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "19615b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-18 13:36:57,050]\u001b[0m A new study created in memory with name: no-name-2c11362e-245b-4d6c-8592-ba88180b9c15\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[32m[I 2023-05-18 13:36:59,701]\u001b[0m Trial 0 finished with value: 435.701416015625 and parameters: {'learning_rate': 5.6115164153345e-05, 'optimizer': 'Adam', 'batch_size': 157, 'RL11': 93, 'RL21': 93, 'RL32': 44, 'RG012': 446, 'RG022': 314, 'RG112': 367, 'RG122': 26}. Best is trial 0 with value: 435.701416015625.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[32m[I 2023-05-18 13:37:01,936]\u001b[0m Trial 1 finished with value: 363.376953125 and parameters: {'learning_rate': 0.0008706020878304854, 'optimizer': 'Adam', 'batch_size': 53, 'RL11': 107, 'RL21': 167, 'RL32': 276, 'RG012': 230, 'RG022': 160, 'RG112': 320, 'RG122': 85}. Best is trial 1 with value: 363.376953125.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[32m[I 2023-05-18 13:37:04,188]\u001b[0m Trial 2 finished with value: 225.87106323242188 and parameters: {'learning_rate': 3.8396292998041685e-05, 'optimizer': 'SGD', 'batch_size': 203, 'RL11': 115, 'RL21': 271, 'RL32': 310, 'RG012': 39, 'RG022': 317, 'RG112': 100, 'RG122': 48}. Best is trial 2 with value: 225.87106323242188.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[32m[I 2023-05-18 13:37:07,095]\u001b[0m Trial 3 finished with value: 264.4226379394531 and parameters: {'learning_rate': 0.000790261954970823, 'optimizer': 'Adam', 'batch_size': 83, 'RL11': 64, 'RL21': 356, 'RL32': 234, 'RG012': 76, 'RG022': 262, 'RG112': 33, 'RG122': 467}. Best is trial 2 with value: 225.87106323242188.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[32m[I 2023-05-18 13:37:09,843]\u001b[0m Trial 4 finished with value: 325.5474853515625 and parameters: {'learning_rate': 3.292759134423613e-05, 'optimizer': 'Adam', 'batch_size': 137, 'RL11': 287, 'RL21': 107, 'RL32': 497, 'RG012': 401, 'RG022': 482, 'RG112': 460, 'RG122': 313}. Best is trial 2 with value: 225.87106323242188.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[32m[I 2023-05-18 13:37:17,379]\u001b[0m Trial 5 finished with value: 389.0024719238281 and parameters: {'learning_rate': 0.0006978281265126031, 'optimizer': 'SGD', 'batch_size': 19, 'RL11': 177, 'RL21': 209, 'RL32': 150, 'RG012': 427, 'RG022': 193, 'RG112': 155, 'RG122': 285}. Best is trial 2 with value: 225.87106323242188.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[32m[I 2023-05-18 13:37:20,365]\u001b[0m Trial 6 finished with value: 593.1698608398438 and parameters: {'learning_rate': 1.913588048769229e-05, 'optimizer': 'Adam', 'batch_size': 253, 'RL11': 399, 'RL21': 114, 'RL32': 18, 'RG012': 421, 'RG022': 367, 'RG112': 378, 'RG122': 399}. Best is trial 2 with value: 225.87106323242188.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[32m[I 2023-05-18 13:37:23,067]\u001b[0m Trial 7 finished with value: 987.8816528320312 and parameters: {'learning_rate': 1.4063366777718176e-05, 'optimizer': 'Adam', 'batch_size': 222, 'RL11': 325, 'RL21': 180, 'RL32': 47, 'RG012': 170, 'RG022': 177, 'RG112': 378, 'RG122': 332}. Best is trial 2 with value: 225.87106323242188.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[32m[I 2023-05-18 13:37:25,805]\u001b[0m Trial 8 finished with value: 250.33340454101562 and parameters: {'learning_rate': 0.000594874681321977, 'optimizer': 'Adam', 'batch_size': 185, 'RL11': 394, 'RL21': 294, 'RL32': 399, 'RG012': 261, 'RG022': 275, 'RG112': 228, 'RG122': 28}. Best is trial 2 with value: 225.87106323242188.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[32m[I 2023-05-18 13:37:28,231]\u001b[0m Trial 9 finished with value: 228.07821655273438 and parameters: {'learning_rate': 1.6435497475111308e-05, 'optimizer': 'SGD', 'batch_size': 86, 'RL11': 268, 'RL21': 467, 'RL32': 139, 'RG012': 219, 'RG022': 391, 'RG112': 129, 'RG122': 54}. Best is trial 2 with value: 225.87106323242188.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[32m[I 2023-05-18 13:37:30,580]\u001b[0m Trial 10 finished with value: 209.75364685058594 and parameters: {'learning_rate': 0.00010649438604541352, 'optimizer': 'SGD', 'batch_size': 207, 'RL11': 181, 'RL21': 409, 'RL32': 348, 'RG012': 23, 'RG022': 44, 'RG112': 34, 'RG122': 177}. Best is trial 10 with value: 209.75364685058594.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[32m[I 2023-05-18 13:37:33,170]\u001b[0m Trial 11 finished with value: 205.8536376953125 and parameters: {'learning_rate': 0.00011605061325789702, 'optimizer': 'SGD', 'batch_size': 201, 'RL11': 176, 'RL21': 419, 'RL32': 344, 'RG012': 21, 'RG022': 19, 'RG112': 20, 'RG122': 178}. Best is trial 11 with value: 205.8536376953125.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-18 13:37:35,760]\u001b[0m Trial 12 finished with value: 227.366455078125 and parameters: {'learning_rate': 0.00014595432633183366, 'optimizer': 'SGD', 'batch_size': 255, 'RL11': 191, 'RL21': 504, 'RL32': 390, 'RG012': 115, 'RG022': 20, 'RG112': 37, 'RG122': 179}. Best is trial 11 with value: 205.8536376953125.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[32m[I 2023-05-18 13:37:38,168]\u001b[0m Trial 13 finished with value: 208.11085510253906 and parameters: {'learning_rate': 0.00013450549446761032, 'optimizer': 'SGD', 'batch_size': 170, 'RL11': 191, 'RL21': 408, 'RL32': 371, 'RG012': 22, 'RG022': 19, 'RG112': 215, 'RG122': 177}. Best is trial 11 with value: 205.8536376953125.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:37:40,720]\u001b[0m Trial 14 failed with parameters: {'learning_rate': 0.0001915975784942856, 'optimizer': 'SGD', 'batch_size': 170, 'RL11': 214, 'RL21': 377, 'RL32': 484, 'RG012': 344, 'RG022': 92, 'RG112': 220, 'RG122': 190} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:37:40,721]\u001b[0m Trial 14 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:37:43,080]\u001b[0m Trial 15 failed with parameters: {'learning_rate': 0.00017128911770316984, 'optimizer': 'SGD', 'batch_size': 159, 'RL11': 501, 'RL21': 382, 'RL32': 454, 'RG012': 133, 'RG022': 92, 'RG112': 224, 'RG122': 186} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:37:43,081]\u001b[0m Trial 15 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:37:45,419]\u001b[0m Trial 16 failed with parameters: {'learning_rate': 0.0002062009247601099, 'optimizer': 'SGD', 'batch_size': 162, 'RL11': 25, 'RL21': 404, 'RL32': 479, 'RG012': 124, 'RG022': 87, 'RG112': 232, 'RG122': 184} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:37:45,421]\u001b[0m Trial 16 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:37:47,761]\u001b[0m Trial 17 failed with parameters: {'learning_rate': 0.00020554959061845843, 'optimizer': 'SGD', 'batch_size': 158, 'RL11': 495, 'RL21': 381, 'RL32': 477, 'RG012': 137, 'RG022': 94, 'RG112': 200, 'RG122': 185} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:37:47,762]\u001b[0m Trial 17 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:37:50,098]\u001b[0m Trial 18 failed with parameters: {'learning_rate': 0.00021104263052157851, 'optimizer': 'SGD', 'batch_size': 170, 'RL11': 215, 'RL21': 394, 'RL32': 476, 'RG012': 340, 'RG022': 109, 'RG112': 223, 'RG122': 186} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:37:50,099]\u001b[0m Trial 18 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:37:52,474]\u001b[0m Trial 19 failed with parameters: {'learning_rate': 0.00018258542254317637, 'optimizer': 'SGD', 'batch_size': 163, 'RL11': 20, 'RL21': 373, 'RL32': 491, 'RG012': 339, 'RG022': 90, 'RG112': 210, 'RG122': 190} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:37:52,475]\u001b[0m Trial 19 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:37:54,872]\u001b[0m Trial 20 failed with parameters: {'learning_rate': 0.00023400383905811692, 'optimizer': 'SGD', 'batch_size': 165, 'RL11': 499, 'RL21': 374, 'RL32': 477, 'RG012': 130, 'RG022': 90, 'RG112': 238, 'RG122': 184} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:37:54,873]\u001b[0m Trial 20 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:37:57,206]\u001b[0m Trial 21 failed with parameters: {'learning_rate': 0.00015655680544242057, 'optimizer': 'SGD', 'batch_size': 165, 'RL11': 488, 'RL21': 381, 'RL32': 473, 'RG012': 332, 'RG022': 82, 'RG112': 217, 'RG122': 180} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:37:57,207]\u001b[0m Trial 21 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:37:59,668]\u001b[0m Trial 22 failed with parameters: {'learning_rate': 0.00017979070120996163, 'optimizer': 'SGD', 'batch_size': 164, 'RL11': 21, 'RL21': 380, 'RL32': 460, 'RG012': 124, 'RG022': 103, 'RG112': 242, 'RG122': 200} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:37:59,668]\u001b[0m Trial 22 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:38:02,021]\u001b[0m Trial 23 failed with parameters: {'learning_rate': 0.0002097851641098602, 'optimizer': 'SGD', 'batch_size': 164, 'RL11': 468, 'RL21': 371, 'RL32': 465, 'RG012': 134, 'RG022': 83, 'RG112': 215, 'RG122': 180} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:38:02,022]\u001b[0m Trial 23 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-05-18 13:38:04,286]\u001b[0m Trial 24 failed with parameters: {'learning_rate': 0.00022165082237284606, 'optimizer': 'SGD', 'batch_size': 162, 'RL11': 18, 'RL21': 383, 'RL32': 474, 'RG012': 342, 'RG022': 87, 'RG112': 225, 'RG122': 188} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:38:04,287]\u001b[0m Trial 24 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:38:06,356]\u001b[0m Trial 25 failed with parameters: {'learning_rate': 0.00018284671996493518, 'optimizer': 'SGD', 'batch_size': 161, 'RL11': 500, 'RL21': 376, 'RL32': 494, 'RG012': 125, 'RG022': 93, 'RG112': 213, 'RG122': 188} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:38:06,357]\u001b[0m Trial 25 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:38:08,611]\u001b[0m Trial 26 failed with parameters: {'learning_rate': 0.00023454808961541, 'optimizer': 'SGD', 'batch_size': 170, 'RL11': 22, 'RL21': 387, 'RL32': 476, 'RG012': 329, 'RG022': 96, 'RG112': 215, 'RG122': 202} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:38:08,612]\u001b[0m Trial 26 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:38:10,920]\u001b[0m Trial 27 failed with parameters: {'learning_rate': 0.0002119677873198492, 'optimizer': 'SGD', 'batch_size': 164, 'RL11': 199, 'RL21': 381, 'RL32': 494, 'RG012': 338, 'RG022': 95, 'RG112': 217, 'RG122': 192} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:38:10,921]\u001b[0m Trial 27 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:38:13,356]\u001b[0m Trial 28 failed with parameters: {'learning_rate': 0.000205519565953418, 'optimizer': 'SGD', 'batch_size': 159, 'RL11': 474, 'RL21': 367, 'RL32': 505, 'RG012': 342, 'RG022': 98, 'RG112': 243, 'RG122': 185} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:38:13,357]\u001b[0m Trial 28 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:38:15,723]\u001b[0m Trial 29 failed with parameters: {'learning_rate': 0.00020294530155587752, 'optimizer': 'SGD', 'batch_size': 164, 'RL11': 482, 'RL21': 378, 'RL32': 474, 'RG012': 324, 'RG022': 87, 'RG112': 225, 'RG122': 192} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:38:15,723]\u001b[0m Trial 29 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:38:18,058]\u001b[0m Trial 30 failed with parameters: {'learning_rate': 0.0002078321936991973, 'optimizer': 'SGD', 'batch_size': 160, 'RL11': 510, 'RL21': 377, 'RL32': 475, 'RG012': 126, 'RG022': 112, 'RG112': 229, 'RG122': 175} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:38:18,059]\u001b[0m Trial 30 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:38:20,433]\u001b[0m Trial 31 failed with parameters: {'learning_rate': 0.0002130633271185402, 'optimizer': 'SGD', 'batch_size': 175, 'RL11': 23, 'RL21': 378, 'RL32': 471, 'RG012': 323, 'RG022': 93, 'RG112': 222, 'RG122': 186} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:38:20,434]\u001b[0m Trial 31 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:38:22,765]\u001b[0m Trial 32 failed with parameters: {'learning_rate': 0.0001950306189510302, 'optimizer': 'SGD', 'batch_size': 160, 'RL11': 27, 'RL21': 368, 'RL32': 473, 'RG012': 329, 'RG022': 88, 'RG112': 232, 'RG122': 187} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:38:22,766]\u001b[0m Trial 32 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:38:25,139]\u001b[0m Trial 33 failed with parameters: {'learning_rate': 0.00016868781594297813, 'optimizer': 'SGD', 'batch_size': 166, 'RL11': 482, 'RL21': 384, 'RL32': 481, 'RG012': 129, 'RG022': 92, 'RG112': 228, 'RG122': 188} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:38:25,140]\u001b[0m Trial 33 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:38:27,541]\u001b[0m Trial 34 failed with parameters: {'learning_rate': 0.00022160819415955783, 'optimizer': 'SGD', 'batch_size': 166, 'RL11': 486, 'RL21': 385, 'RL32': 459, 'RG012': 139, 'RG022': 104, 'RG112': 224, 'RG122': 178} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:38:27,541]\u001b[0m Trial 34 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:38:30,093]\u001b[0m Trial 35 failed with parameters: {'learning_rate': 0.0002352310960673596, 'optimizer': 'SGD', 'batch_size': 166, 'RL11': 217, 'RL21': 395, 'RL32': 472, 'RG012': 120, 'RG022': 101, 'RG112': 221, 'RG122': 183} because of the following error: The value nan is not acceptable..\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-05-18 13:38:30,094]\u001b[0m Trial 35 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:38:32,520]\u001b[0m Trial 36 failed with parameters: {'learning_rate': 0.00019293189794755531, 'optimizer': 'SGD', 'batch_size': 160, 'RL11': 21, 'RL21': 380, 'RL32': 475, 'RG012': 113, 'RG022': 94, 'RG112': 235, 'RG122': 176} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:38:32,521]\u001b[0m Trial 36 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:38:34,948]\u001b[0m Trial 37 failed with parameters: {'learning_rate': 0.00021957336249522625, 'optimizer': 'SGD', 'batch_size': 165, 'RL11': 483, 'RL21': 382, 'RL32': 473, 'RG012': 127, 'RG022': 90, 'RG112': 228, 'RG122': 173} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:38:34,949]\u001b[0m Trial 37 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:38:37,330]\u001b[0m Trial 38 failed with parameters: {'learning_rate': 0.00020018941687883083, 'optimizer': 'SGD', 'batch_size': 169, 'RL11': 497, 'RL21': 396, 'RL32': 484, 'RG012': 117, 'RG022': 94, 'RG112': 226, 'RG122': 196} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:38:37,331]\u001b[0m Trial 38 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:38:39,899]\u001b[0m Trial 39 failed with parameters: {'learning_rate': 0.00019382798143328722, 'optimizer': 'SGD', 'batch_size': 166, 'RL11': 499, 'RL21': 376, 'RL32': 465, 'RG012': 121, 'RG022': 101, 'RG112': 220, 'RG122': 167} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:38:39,901]\u001b[0m Trial 39 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:38:42,411]\u001b[0m Trial 40 failed with parameters: {'learning_rate': 0.00019871752004756567, 'optimizer': 'SGD', 'batch_size': 162, 'RL11': 510, 'RL21': 387, 'RL32': 461, 'RG012': 126, 'RG022': 95, 'RG112': 216, 'RG122': 168} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:38:42,412]\u001b[0m Trial 40 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:38:44,809]\u001b[0m Trial 41 failed with parameters: {'learning_rate': 0.000225360250442197, 'optimizer': 'SGD', 'batch_size': 164, 'RL11': 28, 'RL21': 383, 'RL32': 476, 'RG012': 131, 'RG022': 94, 'RG112': 229, 'RG122': 189} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:38:44,810]\u001b[0m Trial 41 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:38:47,300]\u001b[0m Trial 42 failed with parameters: {'learning_rate': 0.00021650873172218154, 'optimizer': 'SGD', 'batch_size': 159, 'RL11': 213, 'RL21': 385, 'RL32': 480, 'RG012': 135, 'RG022': 102, 'RG112': 221, 'RG122': 168} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:38:47,301]\u001b[0m Trial 42 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:38:49,407]\u001b[0m Trial 43 failed with parameters: {'learning_rate': 0.00021855655028515995, 'optimizer': 'SGD', 'batch_size': 167, 'RL11': 509, 'RL21': 398, 'RL32': 479, 'RG012': 337, 'RG022': 84, 'RG112': 222, 'RG122': 193} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:38:49,408]\u001b[0m Trial 43 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:38:51,590]\u001b[0m Trial 44 failed with parameters: {'learning_rate': 0.00019848723093302925, 'optimizer': 'SGD', 'batch_size': 174, 'RL11': 214, 'RL21': 389, 'RL32': 495, 'RG012': 134, 'RG022': 99, 'RG112': 237, 'RG122': 185} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:38:51,590]\u001b[0m Trial 44 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:38:53,932]\u001b[0m Trial 45 failed with parameters: {'learning_rate': 0.00020883440355869213, 'optimizer': 'SGD', 'batch_size': 166, 'RL11': 495, 'RL21': 370, 'RL32': 490, 'RG012': 130, 'RG022': 110, 'RG112': 214, 'RG122': 190} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:38:53,933]\u001b[0m Trial 45 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:38:56,306]\u001b[0m Trial 46 failed with parameters: {'learning_rate': 0.00017639622895615782, 'optimizer': 'SGD', 'batch_size': 163, 'RL11': 27, 'RL21': 379, 'RL32': 477, 'RG012': 332, 'RG022': 91, 'RG112': 205, 'RG122': 194} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:38:56,307]\u001b[0m Trial 46 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-05-18 13:38:58,683]\u001b[0m Trial 47 failed with parameters: {'learning_rate': 0.00020549770560630956, 'optimizer': 'SGD', 'batch_size': 166, 'RL11': 207, 'RL21': 378, 'RL32': 486, 'RG012': 129, 'RG022': 88, 'RG112': 201, 'RG122': 188} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:38:58,684]\u001b[0m Trial 47 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:39:01,068]\u001b[0m Trial 48 failed with parameters: {'learning_rate': 0.000192119671471052, 'optimizer': 'SGD', 'batch_size': 165, 'RL11': 504, 'RL21': 383, 'RL32': 472, 'RG012': 333, 'RG022': 98, 'RG112': 217, 'RG122': 183} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:39:01,069]\u001b[0m Trial 48 failed with value nan.\u001b[0m\n",
      "/tmp/ipykernel_10110/1969858443.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-3),\n",
      "\u001b[33m[W 2023-05-18 13:39:03,434]\u001b[0m Trial 49 failed with parameters: {'learning_rate': 0.0002031050124258375, 'optimizer': 'SGD', 'batch_size': 167, 'RL11': 481, 'RL21': 370, 'RL32': 469, 'RG012': 142, 'RG022': 95, 'RG112': 223, 'RG122': 199} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-05-18 13:39:03,435]\u001b[0m Trial 49 failed with value nan.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pehe_total=[]\n",
    "for i in range(1,101):\n",
    "    func = lambda trial: objective(trial, i)\n",
    "    study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(seed=42))\n",
    "    study.optimize(func, n_trials=50)\n",
    "    best_trial = study.best_trial\n",
    "    best_model=TarNet(study.best_trial.params)\n",
    "    best_val,model=train_evaluate(study.best_trial.params, best_model, study.best_trial,i)\n",
    "    data,y=get_data('test',i)\n",
    "    pehe=cal_pehe(data,y,model)\n",
    "\n",
    "    pehe_total.append(pehe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a97b7951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9562848210334778\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(pehe_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "aa1f6af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7275428175926208, 0.9615147113800049]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pehe_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e536b889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(pehe_total[0:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6757e606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7245088219642639,\n",
       " 1.0319709777832031,\n",
       " 0.8922997713088989,\n",
       " 0.766045093536377,\n",
       " 1.176272988319397,\n",
       " 1.3779881000518799,\n",
       " 0.33619603514671326,\n",
       " 0.9627038240432739,\n",
       " 0.8635401725769043,\n",
       " 1.3651361465454102,\n",
       " 0.9023053050041199,\n",
       " 0.7707643508911133,\n",
       " 0.6479784250259399,\n",
       " 1.3890775442123413,\n",
       " 1.2930279970169067,\n",
       " 0.8717934489250183,\n",
       " 0.5604594945907593,\n",
       " 0.4141177237033844,\n",
       " 0.9313862323760986,\n",
       " 1.3393807411193848,\n",
       " 0.9354116320610046,\n",
       " 0.5097612142562866,\n",
       " 0.8281165957450867,\n",
       " 0.6784378290176392,\n",
       " 0.9889419674873352,\n",
       " 0.8551837205886841,\n",
       " 0.976718544960022,\n",
       " 0.8554731607437134,\n",
       " 1.5037286281585693,\n",
       " 0.6007119417190552,\n",
       " 0.5339930653572083,\n",
       " 0.6747851967811584,\n",
       " 0.815698504447937,\n",
       " 0.8607384562492371,\n",
       " 0.7166107892990112,\n",
       " 0.6790837049484253,\n",
       " 0.567247748374939,\n",
       " 0.45495477318763733,\n",
       " 1.0859042406082153,\n",
       " 1.9381632804870605,\n",
       " 1.7002204656600952,\n",
       " 0.7606197595596313,\n",
       " 0.34149885177612305,\n",
       " 0.8747959733009338,\n",
       " 0.5832961797714233,\n",
       " 0.5637949705123901,\n",
       " 0.8216122984886169,\n",
       " 1.4024803638458252,\n",
       " 2.833282232284546,\n",
       " 2.11715030670166,\n",
       " 0.9226074814796448,\n",
       " 0.387696236371994,\n",
       " 0.5169910192489624,\n",
       " 2.130324363708496,\n",
       " 0.6147360801696777,\n",
       " 1.5111188888549805,\n",
       " 0.7361528277397156,\n",
       " 1.9234901666641235,\n",
       " 0.44361335039138794,\n",
       " 0.48345568776130676,\n",
       " 0.9034720063209534,\n",
       " 0.3778102695941925,\n",
       " 0.587611973285675,\n",
       " 0.2885318100452423,\n",
       " 0.5243985056877136,\n",
       " 0.9272621870040894,\n",
       " 1.5542900562286377,\n",
       " 0.48880594968795776,\n",
       " 1.0982612371444702,\n",
       " 1.053787112236023,\n",
       " 1.5719798803329468,\n",
       " 1.0619170665740967,\n",
       " 1.243140697479248,\n",
       " 0.7549936771392822,\n",
       " 1.397834300994873,\n",
       " nan,\n",
       " 0.9777540564537048,\n",
       " 1.1433939933776855,\n",
       " 1.078965425491333,\n",
       " 1.3572587966918945,\n",
       " 0.8846351504325867,\n",
       " 2.7632808685302734,\n",
       " 0.7164131999015808,\n",
       " 1.1646203994750977,\n",
       " 0.38471511006355286,\n",
       " 0.9528924822807312,\n",
       " 0.7543814778327942,\n",
       " 19.884397506713867,\n",
       " 0.7215575575828552,\n",
       " 0.5272590517997742,\n",
       " 0.9076446294784546,\n",
       " 0.5668836236000061,\n",
       " 0.35193508863449097,\n",
       " 0.4393121004104614,\n",
       " 0.7004181742668152,\n",
       " 1.843449354171753,\n",
       " 0.7884598970413208,\n",
       " 0.7063225507736206,\n",
       " 0.9662765264511108,\n",
       " 1.3312768936157227]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pehe_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6b002da",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"V2_CFR_y_loss_1_100_(IHDPa-Hyper_val_300ep_outsample).csv\", pehe_total,delimiter =\", \", fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb8e4efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for key, value in best_trial.params.items():\n",
    "#    print(\"{}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f0b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ate_pred=torch.mean(cate_pred)\n",
    "#print(\"Estimated ATE (True is 4):\", ate_pred.detach().numpy(),'\\n\\n')\n",
    "\n",
    "#print(\"Individualized CATE Estimates: BLUE\")\n",
    "#print(pd.Series(cate_pred.detach().numpy()).plot.kde(color='blue'))\n",
    "#print(\"Individualized CATE True: Green\")\n",
    "#print(pd.Series(cate_true.detach().numpy()).plot.kde(color='green'))\n",
    "\n",
    "#print(\"\\nError CATE Estimates: RED\")\n",
    "#print(pd.Series(cate_pred.detach().numpy()-cate_true.detach().numpy()).plot.kde(color='red'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
